def service(action=None, name=None, user=None, create_pid_dir=False, create_log_dir=False):
    import params
    pid_dir = format('{hadoop_pid_dir_prefix}/{user}')
    pid_file = format('{pid_dir}/hadoop-{user}-{name}.pid')
    log_dir = format('{hdfs_log_dir_prefix}/{user}')
    check_process = format('ls {pid_file} >/dev/null 2>&1 && ps `cat {pid_file}` >/dev/null 2>&1')
    if create_pid_dir:
        Directory(pid_dir, owner=user, recursive=True)
    if create_log_dir:
        Directory(log_dir, owner=user, recursive=True)
    hadoop_env_exports = {'HADOOP_LIBEXEC_DIR': params.hadoop_libexec_dir, }
    if (params.security_enabled and (name == 'datanode')):
        dfs_dn_port = get_port(params.dfs_dn_addr)
        dfs_dn_http_port = get_port(params.dfs_dn_http_addr)
        dfs_dn_https_port = get_port(params.dfs_dn_https_addr)
        if (params.dfs_http_policy == 'HTTPS_ONLY'):
            secure_ports_are_in_use = (is_secure_port(dfs_dn_port) or is_secure_port(dfs_dn_https_port))
        elif (params.dfs_http_policy == 'HTTP_AND_HTTPS'):
            secure_ports_are_in_use = (is_secure_port(dfs_dn_port) or is_secure_port(dfs_dn_http_port) or is_secure_port(dfs_dn_https_port))
        else:
            secure_ports_are_in_use = (is_secure_port(dfs_dn_port) or is_secure_port(dfs_dn_http_port))
        hadoop_secure_dn_user = params.hdfs_user
        hadoop_secure_dn_log_dir = format('{hdfs_log_dir_prefix}/{hadoop_secure_dn_user}')
        hadoop_secure_dn_pid_dir = format('{hadoop_pid_dir_prefix}/{hadoop_secure_dn_user}')
        hadoop_secure_dn_exports = {'HADOOP_SECURE_DN_USER': hadoop_secure_dn_user, 'HADOOP_SECURE_DN_LOG_DIR': hadoop_secure_dn_log_dir, 'HADOOP_SECURE_DN_PID_DIR': hadoop_secure_dn_pid_dir, }
        hadoop_secure_dn_pid_file = format('{hadoop_secure_dn_pid_dir}/hadoop_secure_dn.pid')
        if ((not params.stack_is_hdp22_or_further) or secure_ports_are_in_use):
            user = 'root'
            pid_file = format('{hadoop_pid_dir_prefix}/{hdfs_user}/hadoop-{hdfs_user}-{name}.pid')
            if params.stack_is_hdp22_or_further:
                hadoop_env_exports.update(hadoop_secure_dn_exports)
        if ((action == 'stop') and params.stack_is_hdp22_or_further and os.path.isfile(hadoop_secure_dn_pid_file)):
            user = 'root'
            try:
                with open(hadoop_secure_dn_pid_file, 'r') as f:
                    pid = f.read()
                os.kill(int(pid), 0)
                hadoop_env_exports.update(hadoop_secure_dn_exports)
            except IOError:
                pass
            except ValueError:
                pass
            except OSError:
                pass
    hadoop_env_exports_str = ''
    for exp in hadoop_env_exports.items():
        hadoop_env_exports_str += 'export {0}={1} && '.format(exp[0], exp[1])
    hadoop_daemon = format('{hadoop_env_exports_str}{hadoop_bin}/hadoop-daemon.sh')
    cmd = format('{hadoop_daemon} --config {hadoop_conf_dir}')
    daemon_cmd = format("{ulimit_cmd} su -s /bin/bash - {user} -c '{cmd} {action} {name}'")
    service_is_up = (check_process if (action == 'start') else None)
    File(pid_file, action='delete', not_if=check_process)
    Execute(daemon_cmd, not_if=service_is_up)
    if (action == 'stop'):
        File(pid_file, action='delete')
