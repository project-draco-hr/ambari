@patch('resource_management.libraries.functions.copy_tarball.copy_to_hdfs')
def test_start_default(self, copy_to_hdfs_mock):
    copy_to_hdfs_mock.return_value = True
    self.executeScript((self.COMMON_SERVICES_PACKAGE_DIR + '/scripts/job_history_server.py'), classname='JobHistoryServer', command='start', config_file='default.json', hdp_stack_version=self.STACK_VERSION, target=RMFTestCase.TARGET_COMMON_SERVICES)
    self.assert_configure_default()
    self.assertResourceCalled('HdfsResource', None, security_enabled=False, hadoop_bin_dir='/usr/hdp/current/hadoop-client/bin', keytab=UnknownConfigurationMock(), default_fs='hdfs://c6401.ambari.apache.org:8020', hdfs_site={u'a': u'b', }, kinit_path_local='/usr/bin/kinit', principal_name=UnknownConfigurationMock(), user='hdfs', action=['execute'], hadoop_conf_dir='/usr/hdp/current/hadoop-client/conf')
    self.assertResourceCalled('Execute', '/usr/hdp/current/spark-client/sbin/start-history-server.sh', environment={'JAVA_HOME': u'/usr/jdk64/jdk1.7.0_45', }, not_if='ls /var/run/spark/spark-spark-org.apache.spark.deploy.history.HistoryServer-1.pid >/dev/null 2>&1 && ps -p `cat /var/run/spark/spark-spark-org.apache.spark.deploy.history.HistoryServer-1.pid` >/dev/null 2>&1', user='spark')
    self.assertNoMoreResources()
