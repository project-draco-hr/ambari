def assert_configure_default(self):
    self.assertResourceCalled('Directory', '/var/run/spark', owner='spark', group='hadoop', create_parents=True, mode=509)
    self.assertResourceCalled('Directory', '/var/log/spark', owner='spark', group='hadoop', create_parents=True, mode=509)
    self.assertResourceCalled('HdfsResource', '/user/spark', immutable_paths=self.DEFAULT_IMMUTABLE_PATHS, security_enabled=False, hadoop_bin_dir='/usr/hdp/current/hadoop-client/bin', keytab=UnknownConfigurationMock(), default_fs='hdfs://c6401.ambari.apache.org:8020', hdfs_site={u'a': u'b', }, kinit_path_local='/usr/bin/kinit', principal_name=UnknownConfigurationMock(), user='hdfs', dfs_type='', owner='spark', hadoop_conf_dir='/usr/hdp/current/hadoop-client/conf', type='directory', action=['create_on_execute'], hdfs_resource_ignore_file='/var/lib/ambari-agent/data/.hdfs_resource_ignore', mode=509)
    self.assertResourceCalled('HdfsResource', None, immutable_paths=self.DEFAULT_IMMUTABLE_PATHS, security_enabled=False, hadoop_bin_dir='/usr/hdp/current/hadoop-client/bin', keytab=UnknownConfigurationMock(), default_fs='hdfs://c6401.ambari.apache.org:8020', hdfs_site={u'a': u'b', }, kinit_path_local='/usr/bin/kinit', principal_name=UnknownConfigurationMock(), user='hdfs', dfs_type='', action=['execute'], hdfs_resource_ignore_file='/var/lib/ambari-agent/data/.hdfs_resource_ignore', hadoop_conf_dir='/usr/hdp/current/hadoop-client/conf')
    self.assertResourceCalled('PropertiesFile', '/usr/hdp/current/spark-client/conf/spark-defaults.conf', owner='spark', key_value_delimiter=' ', group='spark', properties=self.getConfig()['configurations']['spark-defaults'])
    self.assertResourceCalled('File', '/usr/hdp/current/spark-client/conf/spark-env.sh', content=InlineTemplate(self.getConfig()['configurations']['spark-env']['content']), owner='spark', group='spark', mode=420)
    self.assertResourceCalled('File', '/usr/hdp/current/spark-client/conf/log4j.properties', content='\n# Set everything to be logged to the console\nlog4j.rootCategory=INFO, console\nlog4j.appender.console=org.apache.log4j.ConsoleAppender\nlog4j.appender.console.target=System.err\nlog4j.appender.console.layout=org.apache.log4j.PatternLayout\nlog4j.appender.console.layout.ConversionPattern=%d{yy/MM/dd HH:mm:ss} %p %c{1}: %m%n\n\n# Settings to quiet third party logs that are too verbose\nlog4j.logger.org.eclipse.jetty=WARN\nlog4j.logger.org.eclipse.jetty.util.component.AbstractLifeCycle=ERROR\nlog4j.logger.org.apache.spark.repl.SparkIMain$exprTyper=INFO\nlog4j.logger.org.apache.spark.repl.SparkILoop$SparkILoopInterpreter=INFO', owner='spark', group='spark', mode=420)
    self.assertResourceCalled('File', '/usr/hdp/current/spark-client/conf/metrics.properties', content=InlineTemplate(self.getConfig()['configurations']['spark-metrics-properties']['content']), owner='spark', group='spark')
    self.assertResourceCalled('File', '/usr/hdp/current/spark-client/conf/java-opts', content=InlineTemplate(' '), owner='spark', group='spark')
    self.assertResourceCalled('Directory', '/usr/hdp/current/spark-client/logs', owner='spark', group='spark', mode=493)
