@patch('resource_management.libraries.functions.copy_tarball.copy_to_hdfs')
def test_pre_rolling_restart_23(self, copy_to_hdfs_mock):
    config_file = (self.get_src_folder() + '/test/python/stacks/2.2/configs/default.json')
    with open(config_file, 'r') as f:
        json_content = json.load(f)
    version = '2.3.0.0-1234'
    json_content['commandParams']['version'] = version
    copy_to_hdfs_mock.return_value = True
    mocks_dict = {}
    self.executeScript((self.COMMON_SERVICES_PACKAGE_DIR + '/scripts/job_history_server.py'), classname='JobHistoryServer', command='pre_rolling_restart', config_dict=json_content, hdp_stack_version=self.STACK_VERSION, target=RMFTestCase.TARGET_COMMON_SERVICES, call_mocks=[(0, None), (0, None)], mocks_dict=mocks_dict)
    self.assertResourceCalled('Execute', 'hdp-select set spark-historyserver {0}'.format(version))
    copy_to_hdfs_mock.assert_called_with('tez', 'hadoop', 'hdfs')
    self.assertResourceCalled('HdfsResource', None, security_enabled=False, hadoop_bin_dir='/usr/hdp/current/hadoop-client/bin', keytab=UnknownConfigurationMock(), kinit_path_local='/usr/bin/kinit', user='hdfs', action=['execute'], hdfs_site=self.getConfig()['configurations']['hdfs-site'], principal_name=UnknownConfigurationMock(), default_fs='hdfs://c6401.ambari.apache.org:8020', hadoop_conf_dir='/usr/hdp/current/hadoop-client/conf')
    self.assertNoMoreResources()
    self.assertEquals(2, mocks_dict['call'].call_count)
    self.assertEquals('conf-select create-conf-dir --package spark --stack-version 2.3.0.0-1234 --conf-version 0', mocks_dict['call'].call_args_list[0][0][0])
    self.assertEquals('conf-select set-conf-dir --package spark --stack-version 2.3.0.0-1234 --conf-version 0', mocks_dict['call'].call_args_list[1][0][0])
