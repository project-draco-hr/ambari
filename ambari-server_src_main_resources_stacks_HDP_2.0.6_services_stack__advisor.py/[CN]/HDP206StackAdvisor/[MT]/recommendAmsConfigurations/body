def recommendAmsConfigurations(self, configurations, clusterData, services, hosts):
    putAmsEnvProperty = self.putProperty(configurations, 'ams-env', services)
    putAmsHbaseSiteProperty = self.putProperty(configurations, 'ams-hbase-site', services)
    putTimelineServiceProperty = self.putProperty(configurations, 'ams-site', services)
    putHbaseEnvProperty = self.putProperty(configurations, 'ams-hbase-env', services)
    amsCollectorHosts = self.getComponentHostNames(services, 'AMBARI_METRICS', 'METRICS_COLLECTOR')
    rootDir = 'file:///var/lib/ambari-metrics-collector/hbase'
    tmpDir = '/var/lib/ambari-metrics-collector/hbase-tmp'
    if ('ams-hbase-site' in services['configurations']):
        if ('hbase.rootdir' in services['configurations']['ams-hbase-site']['properties']):
            rootDir = services['configurations']['ams-hbase-site']['properties']['hbase.rootdir']
        if ('hbase.tmp.dir' in services['configurations']['ams-hbase-site']['properties']):
            tmpDir = services['configurations']['ams-hbase-site']['properties']['hbase.tmp.dir']
    mountpoints = ['/']
    for collectorHostName in amsCollectorHosts:
        for host in hosts['items']:
            if (host['Hosts']['host_name'] == collectorHostName):
                mountpoints = self.getPreferredMountPoints(host['Hosts'])
                break
    if (not rootDir.startswith('hdfs://')):
        rootDir = re.sub('^file:///|/', '', rootDir, count=1)
        rootDir = ('file://' + os.path.join(mountpoints[0], rootDir))
    tmpDir = re.sub('^file:///|/', '', tmpDir, count=1)
    if ((len(mountpoints) > 1) and (not rootDir.startswith('hdfs://'))):
        tmpDir = os.path.join(mountpoints[1], tmpDir)
    else:
        tmpDir = os.path.join(mountpoints[0], tmpDir)
    putAmsHbaseSiteProperty('hbase.rootdir', rootDir)
    putAmsHbaseSiteProperty('hbase.tmp.dir', tmpDir)
    (collector_heapsize, hbase_heapsize, total_sinks_count) = self.getAmsMemoryRecommendation(services, hosts)
    putAmsEnvProperty('metrics_collector_heapsize', (str(collector_heapsize) + 'm'))
    putAmsHbaseSiteProperty('hfile.block.cache.size', 0.3)
    putAmsHbaseSiteProperty('hbase.hregion.memstore.flush.size', 134217728)
    putAmsHbaseSiteProperty('hbase.regionserver.global.memstore.upperLimit', 0.35)
    putAmsHbaseSiteProperty('hbase.regionserver.global.memstore.lowerLimit', 0.3)
    putTimelineServiceProperty('timeline.metrics.host.aggregator.ttl', 86400)
    if rootDir.startswith('hdfs://'):
        putHbaseEnvProperty('hbase_master_heapsize', '512m')
        putHbaseEnvProperty('hbase_regionserver_heapsize', (str(hbase_heapsize) + 'm'))
    else:
        putHbaseEnvProperty('hbase_master_heapsize', (str(hbase_heapsize) + 'm'))
    if (len(amsCollectorHosts) > 1):
        pass
    else:
        if (total_sinks_count >= 2000):
            putAmsHbaseSiteProperty('hbase.regionserver.handler.count', 60)
            putAmsHbaseSiteProperty('hbase.regionserver.hlog.blocksize', 134217728)
            putAmsHbaseSiteProperty('hbase.regionserver.maxlogs', 64)
            putAmsHbaseSiteProperty('hbase.hregion.memstore.flush.size', 268435456)
            putAmsHbaseSiteProperty('hbase.regionserver.global.memstore.upperLimit', 0.3)
            putAmsHbaseSiteProperty('hbase.regionserver.global.memstore.lowerLimit', 0.25)
            putAmsHbaseSiteProperty('phoenix.query.maxGlobalMemoryPercentage', 20)
            putTimelineServiceProperty('phoenix.query.maxGlobalMemoryPercentage', 30)
            putAmsHbaseSiteProperty('hbase_master_xmn_size', '512m')
            putAmsHbaseSiteProperty('regionserver_xmn_size', '512m')
        elif (total_sinks_count >= 500):
            putAmsHbaseSiteProperty('hbase.regionserver.handler.count', 60)
            putAmsHbaseSiteProperty('hbase.regionserver.hlog.blocksize', 134217728)
            putAmsHbaseSiteProperty('hbase.regionserver.maxlogs', 64)
            putAmsHbaseSiteProperty('hbase.hregion.memstore.flush.size', 268435456)
            putAmsHbaseSiteProperty('hbase_master_xmn_size', '512m')
        elif (total_sinks_count >= 250):
            putAmsHbaseSiteProperty('hbase_master_xmn_size', '256m')
        else:
            putAmsHbaseSiteProperty('hbase_master_xmn_size', '128m')
        pass
    scriptDir = os.path.dirname(os.path.abspath(__file__))
    metricsDir = os.path.join(scriptDir, '../../../../common-services/AMBARI_METRICS/0.1.0/package')
    serviceMetricsDir = os.path.join(metricsDir, 'files', 'service-metrics')
    sys.path.append(os.path.join(metricsDir, 'scripts'))
    mode = ('distributed' if rootDir.startswith('hdfs://') else 'embedded')
    servicesList = [service['StackServices']['service_name'] for service in services['services']]
    from split_points import FindSplitPointsForAMSRegions
    ams_hbase_site = None
    ams_hbase_env = None
    if ('ams-hbase-site' in services['configurations']):
        ams_hbase_site = services['configurations']['ams-hbase-site']['properties']
    if ('ams-hbase-env' in services['configurations']):
        ams_hbase_env = services['configurations']['ams-hbase-env']['properties']
    if (not ams_hbase_site):
        ams_hbase_site = configurations['ams-hbase-site']['properties']
    if (not ams_hbase_env):
        ams_hbase_env = configurations['ams-hbase-env']['properties']
    split_point_finder = FindSplitPointsForAMSRegions(ams_hbase_site, ams_hbase_env, serviceMetricsDir, mode, servicesList)
    result = split_point_finder.get_split_points()
    precision_splits = ' '
    aggregate_splits = ' '
    if result.precision:
        precision_splits = result.precision
    if result.aggregate:
        aggregate_splits = result.aggregate
    putTimelineServiceProperty('timeline.metrics.host.aggregate.splitpoints', ','.join(precision_splits))
    putTimelineServiceProperty('timeline.metrics.cluster.aggregate.splitpoints', ','.join(aggregate_splits))
    pass
