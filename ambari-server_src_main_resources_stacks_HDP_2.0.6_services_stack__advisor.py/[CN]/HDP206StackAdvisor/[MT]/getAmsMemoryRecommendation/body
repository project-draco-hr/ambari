def getAmsMemoryRecommendation(self, services, hosts):
    HEAP_PER_MASTER_COMPONENT = 50
    HEAP_PER_SLAVE_COMPONENT = 10
    schMemoryMap = {'HDFS': {'NAMENODE': HEAP_PER_MASTER_COMPONENT, 'DATANODE': HEAP_PER_SLAVE_COMPONENT, }, 'YARN': {'RESOURCEMANAGER': HEAP_PER_MASTER_COMPONENT, }, 'HBASE': {'HBASE_MASTER': HEAP_PER_MASTER_COMPONENT, 'HBASE_REGIONSERVER': HEAP_PER_SLAVE_COMPONENT, }, 'ACCUMULO': {'ACCUMULO_MASTER': HEAP_PER_MASTER_COMPONENT, 'ACCUMULO_TSERVER': HEAP_PER_SLAVE_COMPONENT, }, 'KAFKA': {'KAFKA_BROKER': HEAP_PER_MASTER_COMPONENT, }, 'FLUME': {'FLUME_HANDLER': HEAP_PER_SLAVE_COMPONENT, }, 'STORM': {'NIMBUS': HEAP_PER_MASTER_COMPONENT, }, 'AMBARI_METRICS': {'METRICS_COLLECTOR': HEAP_PER_MASTER_COMPONENT, 'METRICS_MONITOR': HEAP_PER_SLAVE_COMPONENT, }, }
    total_sinks_count = 0
    hbase_heapsize = 500
    for (serviceName, componentsDict) in schMemoryMap.items():
        for (componentName, multiplier) in componentsDict.items():
            schCount = len(self.getHostsWithComponent(serviceName, componentName, services, hosts))
            hbase_heapsize += int(((schCount * multiplier) ** 0.9))
            total_sinks_count += schCount
    collector_heapsize = int(((hbase_heapsize / 4) if (hbase_heapsize > 2048) else 512))
    return (collector_heapsize, hbase_heapsize, total_sinks_count)
