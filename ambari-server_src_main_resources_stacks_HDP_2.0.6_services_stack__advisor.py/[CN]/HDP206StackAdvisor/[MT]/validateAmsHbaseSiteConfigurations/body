def validateAmsHbaseSiteConfigurations(self, properties, recommendedDefaults, configurations, services, hosts):
    amsCollectorHosts = self.getComponentHostNames(services, 'AMBARI_METRICS', 'METRICS_COLLECTOR')
    ams_site = getSiteProperties(configurations, 'ams-site')
    (collector_heapsize, hbase_heapsize, total_sinks_count) = self.getAmsMemoryRecommendation(services, hosts)
    recommendedDiskSpace = 10485760
    if (len(amsCollectorHosts) > 1):
        pass
    elif (total_sinks_count > 2000):
        recommendedDiskSpace = 104857600
    elif (total_sinks_count > 500):
        recommendedDiskSpace = 52428800
    elif (total_sinks_count > 250):
        recommendedDiskSpace = 20971520
    validationItems = []
    rootdir_item = None
    op_mode = ams_site.get('timeline.metrics.service.operation.mode')
    hbase_rootdir = properties.get('hbase.rootdir')
    if ((op_mode == 'distributed') and (not hbase_rootdir.startswith('hdfs://'))):
        rootdir_item = self.getWarnItem('In distributed mode hbase.rootdir should point to HDFS. Collector will operate in embedded mode otherwise.')
        pass
    distributed_item = None
    distributed = properties.get('hbase.cluster.distributed')
    if (hbase_rootdir and hbase_rootdir.startswith('hdfs://') and (not (distributed.lower() == 'true'))):
        distributed_item = self.getErrorItem('Distributed property should be set to true if hbase.rootdir points to HDFS.')
    validationItems.extend([{'config-name': 'hbase.rootdir', 'item': rootdir_item, }, {'config-name': 'hbase.cluster.distributed', 'item': distributed_item, }])
    for collectorHostName in amsCollectorHosts:
        for host in hosts['items']:
            if (host['Hosts']['host_name'] == collectorHostName):
                validationItems.extend([{'config-name': 'hbase.rootdir', 'item': self.validatorEnoughDiskSpace(properties, 'hbase.rootdir', host['Hosts'], recommendedDiskSpace), }])
                validationItems.extend([{'config-name': 'hbase.rootdir', 'item': self.validatorNotRootFs(properties, 'hbase.rootdir', host['Hosts']), }])
                validationItems.extend([{'config-name': 'hbase.tmp.dir', 'item': self.validatorNotRootFs(properties, 'hbase.tmp.dir', host['Hosts']), }])
                dn_hosts = self.getComponentHostNames(services, 'HDFS', 'DATANODE')
                if ((not hbase_rootdir.startswith('hdfs')) and dn_hosts and (collectorHostName in dn_hosts)):
                    hdfs_site = getSiteProperties(configurations, 'hdfs-site')
                    mountPoints = []
                    for mountPoint in host['Hosts']['disk_info']:
                        mountPoints.append(mountPoint['mountpoint'])
                    hbase_rootdir_mountpoint = getMountPointForDir(hbase_rootdir, mountPoints)
                    if (ams_site and hdfs_site and ('dfs.datanode.data.dir' in hdfs_site)):
                        for dfs_datadir in hdfs_site.get('dfs.datanode.data.dir').split(','):
                            mountPoints = []
                            for mountPoint in host['Hosts']['disk_info']:
                                mountPoints.append(mountPoint['mountpoint'])
                            dfs_datadir_mountpoint = getMountPointForDir(dfs_datadir, mountPoints)
                            if (dfs_datadir_mountpoint == hbase_rootdir_mountpoint):
                                item = self.getWarnItem('Consider not using {0} partition for storing metrics data. {0} is already used by datanode to store HDFS data'.format(hbase_rootdir_mountpoint))
                                validationItems.extend([{'config-name': 'hbase.rootdir', 'item': item, }])
                                break
    return self.toConfigurationValidationProblems(validationItems, 'ams-hbase-site')
