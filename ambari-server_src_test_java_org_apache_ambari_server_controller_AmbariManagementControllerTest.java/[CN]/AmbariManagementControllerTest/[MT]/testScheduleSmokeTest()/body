{
  final String HOST1="host1";
  final String OS_TYPE="centos5";
  final String STACK_ID="HDP-2.0.1";
  final String CLUSTER_NAME="c1";
  final String HDFS_SERVICE_CHECK_ROLE="HDFS_SERVICE_CHECK";
  final String MAPREDUCE2_SERVICE_CHECK_ROLE="MAPREDUCE2_SERVICE_CHECK";
  final String YARN_SERVICE_CHECK_ROLE="YARN_SERVICE_CHECK";
  Map<String,String> mapRequestProps=Collections.emptyMap();
  Injector injector=Guice.createInjector(new AbstractModule(){
    @Override protected void configure(){
      Properties properties=new Properties();
      properties.setProperty(Configuration.SERVER_PERSISTENCE_TYPE_KEY,"in-memory");
      properties.setProperty(Configuration.METADETA_DIR_PATH,"src/test/resources/stacks");
      properties.setProperty(Configuration.SERVER_VERSION_FILE,"../version");
      properties.setProperty(Configuration.OS_VERSION_KEY,OS_TYPE);
      try {
        install(new ControllerModule(properties));
      }
 catch (      Exception e) {
        throw new RuntimeException(e);
      }
    }
  }
);
  injector.getInstance(GuiceJpaInitializer.class);
  try {
    AmbariManagementController amc=injector.getInstance(AmbariManagementController.class);
    Clusters clusters=injector.getInstance(Clusters.class);
    clusters.addHost(HOST1);
    Host host=clusters.getHost(HOST1);
    host.setOsType(OS_TYPE);
    host.persist();
    ClusterRequest clusterRequest=new ClusterRequest(null,CLUSTER_NAME,STACK_ID,null);
    amc.createCluster(clusterRequest);
    Set<ServiceRequest> serviceRequests=new HashSet<ServiceRequest>();
    serviceRequests.add(new ServiceRequest(CLUSTER_NAME,"HDFS",null));
    serviceRequests.add(new ServiceRequest(CLUSTER_NAME,"MAPREDUCE2",null));
    serviceRequests.add(new ServiceRequest(CLUSTER_NAME,"YARN",null));
    ServiceResourceProviderTest.createServices(amc,serviceRequests);
    Set<ServiceComponentRequest> serviceComponentRequests=new HashSet<ServiceComponentRequest>();
    serviceComponentRequests.add(new ServiceComponentRequest(CLUSTER_NAME,"HDFS","NAMENODE",null));
    serviceComponentRequests.add(new ServiceComponentRequest(CLUSTER_NAME,"HDFS","SECONDARY_NAMENODE",null));
    serviceComponentRequests.add(new ServiceComponentRequest(CLUSTER_NAME,"HDFS","DATANODE",null));
    serviceComponentRequests.add(new ServiceComponentRequest(CLUSTER_NAME,"MAPREDUCE2","HISTORYSERVER",null));
    serviceComponentRequests.add(new ServiceComponentRequest(CLUSTER_NAME,"YARN","RESOURCEMANAGER",null));
    serviceComponentRequests.add(new ServiceComponentRequest(CLUSTER_NAME,"YARN","NODEMANAGER",null));
    ComponentResourceProviderTest.createComponents(amc,serviceComponentRequests);
    Set<HostRequest> hostRequests=new HashSet<HostRequest>();
    hostRequests.add(new HostRequest(HOST1,CLUSTER_NAME,null));
    HostResourceProviderTest.createHosts(amc,hostRequests);
    Set<ServiceComponentHostRequest> componentHostRequests=new HashSet<ServiceComponentHostRequest>();
    componentHostRequests.add(new ServiceComponentHostRequest(CLUSTER_NAME,null,"DATANODE",HOST1,null));
    componentHostRequests.add(new ServiceComponentHostRequest(CLUSTER_NAME,null,"NAMENODE",HOST1,null));
    componentHostRequests.add(new ServiceComponentHostRequest(CLUSTER_NAME,null,"SECONDARY_NAMENODE",HOST1,null));
    componentHostRequests.add(new ServiceComponentHostRequest(CLUSTER_NAME,null,"HISTORYSERVER",HOST1,null));
    componentHostRequests.add(new ServiceComponentHostRequest(CLUSTER_NAME,null,"RESOURCEMANAGER",HOST1,null));
    componentHostRequests.add(new ServiceComponentHostRequest(CLUSTER_NAME,null,"NODEMANAGER",HOST1,null));
    amc.createHostComponents(componentHostRequests);
    serviceRequests.clear();
    serviceRequests.add(new ServiceRequest(CLUSTER_NAME,"HDFS",State.INSTALLED.name()));
    serviceRequests.add(new ServiceRequest(CLUSTER_NAME,"MAPREDUCE2",State.INSTALLED.name()));
    serviceRequests.add(new ServiceRequest(CLUSTER_NAME,"YARN",State.INSTALLED.name()));
    ServiceResourceProviderTest.updateServices(amc,serviceRequests,mapRequestProps,true,false);
    Cluster cluster=clusters.getCluster(CLUSTER_NAME);
    for (    String serviceName : cluster.getServices().keySet()) {
      for (      String componentName : cluster.getService(serviceName).getServiceComponents().keySet()) {
        Map<String,ServiceComponentHost> serviceComponentHosts=cluster.getService(serviceName).getServiceComponent(componentName).getServiceComponentHosts();
        for (        Map.Entry<String,ServiceComponentHost> entry : serviceComponentHosts.entrySet()) {
          ServiceComponentHost cHost=entry.getValue();
          cHost.handleEvent(new ServiceComponentHostInstallEvent(cHost.getServiceComponentName(),cHost.getHostName(),System.currentTimeMillis(),STACK_ID));
          cHost.handleEvent(new ServiceComponentHostOpSucceededEvent(cHost.getServiceComponentName(),cHost.getHostName(),System.currentTimeMillis()));
        }
      }
    }
    serviceRequests.clear();
    serviceRequests.add(new ServiceRequest(CLUSTER_NAME,"HDFS",State.STARTED.name()));
    serviceRequests.add(new ServiceRequest(CLUSTER_NAME,"MAPREDUCE2",State.STARTED.name()));
    serviceRequests.add(new ServiceRequest(CLUSTER_NAME,"YARN",State.STARTED.name()));
    RequestStatusResponse response=ServiceResourceProviderTest.updateServices(amc,serviceRequests,mapRequestProps,true,false);
    Collection<?> hdfsSmokeTasks=CollectionUtils.select(response.getTasks(),new RolePredicate(HDFS_SERVICE_CHECK_ROLE));
    org.junit.Assert.assertEquals(1,hdfsSmokeTasks.size());
    Collection<?> mapreduce2SmokeTasks=CollectionUtils.select(response.getTasks(),new RolePredicate(MAPREDUCE2_SERVICE_CHECK_ROLE));
    org.junit.Assert.assertEquals(1,mapreduce2SmokeTasks.size());
    Collection<?> yarnSmokeTasks=CollectionUtils.select(response.getTasks(),new RolePredicate(YARN_SERVICE_CHECK_ROLE));
    org.junit.Assert.assertEquals(1,yarnSmokeTasks.size());
  }
  finally {
    injector.getInstance(PersistService.class).stop();
  }
}
