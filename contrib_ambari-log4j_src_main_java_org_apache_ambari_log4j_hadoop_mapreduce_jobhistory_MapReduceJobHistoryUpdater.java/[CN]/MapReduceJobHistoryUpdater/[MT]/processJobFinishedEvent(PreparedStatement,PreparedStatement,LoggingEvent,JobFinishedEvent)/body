{
  Counters counters=historyEvent.getMapCounters();
  long inputBytes=0;
  if (counters != null) {
    for (    CounterGroup group : counters) {
      for (      Counter counter : group) {
        if (counter.getName().equals("HDFS_BYTES_READ"))         inputBytes+=counter.getValue();
      }
    }
  }
  if (historyEvent.getFinishedReduces() != 0)   counters=historyEvent.getReduceCounters();
  long outputBytes=0;
  if (counters != null) {
    for (    CounterGroup group : counters) {
      for (      Counter counter : group) {
        if (counter.getName().equals("HDFS_BYTES_WRITTEN"))         outputBytes+=counter.getValue();
      }
    }
  }
  try {
    entityPS.setLong(1,historyEvent.getFinishTime());
    entityPS.setInt(2,historyEvent.getFinishedMaps());
    entityPS.setInt(3,historyEvent.getFinishedReduces());
    entityPS.setInt(4,historyEvent.getFailedMaps());
    entityPS.setInt(5,historyEvent.getFailedReduces());
    entityPS.setLong(6,inputBytes);
    entityPS.setLong(7,outputBytes);
    entityPS.setString(8,historyEvent.getJobid().toString());
    entityPS.executeUpdate();
    workflowUpdateNumCompletedPS.setString(1,historyEvent.getJobid().toString());
    workflowUpdateNumCompletedPS.setLong(2,historyEvent.getFinishTime());
    workflowUpdateNumCompletedPS.setLong(3,historyEvent.getFinishTime());
    workflowUpdateNumCompletedPS.executeUpdate();
  }
 catch (  SQLException sqle) {
    LOG.info("Failed to store " + historyEvent.getEventType() + " for job "+ historyEvent.getJobid()+ " into "+ JOB_TABLE,sqle);
  }
  updateJobStatsAtFinish(historyEvent.getJobid().toString());
}
