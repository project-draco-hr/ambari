@patch('hdfs_nfsgateway.prepare_rpcbind')
def test_start_secured(self, prepare_rpcbind_mock):
    prepare_rpcbind_mock.returnvalue = 0
    self.executeScript((self.COMMON_SERVICES_PACKAGE_DIR + '/scripts/nfsgateway.py'), classname='NFSGateway', command='start', config_file='secured.json', stack_version=self.STACK_VERSION, target=RMFTestCase.TARGET_COMMON_SERVICES)
    self.assert_configure_secured()
    self.assertResourceCalled('Directory', '/var/run/hadoop', owner='root', group='root', mode=493)
    self.assertResourceCalled('Directory', '/var/run/hadoop/root', owner='root', create_parents=True)
    self.assertResourceCalled('Directory', '/var/log/hadoop/root', owner='root', group='hadoop', mode=509)
    self.assertResourceCalled('File', '/var/run/hadoop/root/hadoop_privileged_nfs3.pid', action=['delete'], not_if='ambari-sudo.sh [RMF_ENV_PLACEHOLDER] -H -E test -f /var/run/hadoop/root/hadoop_privileged_nfs3.pid && ambari-sudo.sh [RMF_ENV_PLACEHOLDER] -H -E pgrep -F /var/run/hadoop/root/hadoop_privileged_nfs3.pid')
    self.assertResourceCalled('Execute', 'ambari-sudo.sh [RMF_ENV_PLACEHOLDER] -H -E /usr/lib/hadoop/sbin/hadoop-daemon.sh --config /etc/hadoop/conf start nfs3', environment={'HADOOP_LIBEXEC_DIR': '/usr/lib/hadoop/libexec', 'HADOOP_PRIVILEGED_NFS_LOG_DIR': u'/var/log/hadoop/root', 'HADOOP_PRIVILEGED_NFS_PID_DIR': u'/var/run/hadoop/root', 'HADOOP_PRIVILEGED_NFS_USER': u'hdfs', }, not_if='ambari-sudo.sh [RMF_ENV_PLACEHOLDER] -H -E test -f /var/run/hadoop/root/hadoop_privileged_nfs3.pid && ambari-sudo.sh [RMF_ENV_PLACEHOLDER] -H -E pgrep -F /var/run/hadoop/root/hadoop_privileged_nfs3.pid')
    self.assertNoMoreResources()
