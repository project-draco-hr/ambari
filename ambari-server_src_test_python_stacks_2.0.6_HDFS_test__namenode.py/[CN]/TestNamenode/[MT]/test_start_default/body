def test_start_default(self):
    self.executeScript((self.COMMON_SERVICES_PACKAGE_DIR + '/scripts/namenode.py'), classname='NameNode', command='start', config_file='default.json', hdp_stack_version=self.STACK_VERSION, target=RMFTestCase.TARGET_COMMON_SERVICES)
    self.assert_configure_default()
    self.assertResourceCalled('File', '/tmp/checkForFormat.sh', content=StaticFile('checkForFormat.sh'), mode=493)
    self.assertResourceCalled('Execute', '/tmp/checkForFormat.sh hdfs /etc/hadoop/conf /usr/bin /var/run/hadoop/hdfs/namenode/formatted/ /var/lib/hdfs/namenode/formatted/ /hadoop/hdfs/namenode', path=['/usr/sbin:/sbin:/usr/local/bin:/bin:/usr/bin'], not_if='test -d /var/run/hadoop/hdfs/namenode/formatted/ || test -d /var/lib/hdfs/namenode/formatted/')
    self.assertResourceCalled('Directory', '/var/lib/hdfs/namenode/formatted/', recursive=True)
    self.assertResourceCalled('File', '/etc/hadoop/conf/dfs.exclude', owner='hdfs', content=Template('exclude_hosts_list.j2'), group='hadoop')
    self.assertResourceCalled('Directory', '/var/run/hadoop', owner='hdfs', group='hadoop', mode=493)
    self.assertResourceCalled('Directory', '/var/run/hadoop/hdfs', owner='hdfs', recursive=True)
    self.assertResourceCalled('Directory', '/var/log/hadoop/hdfs', owner='hdfs', recursive=True)
    self.assertResourceCalled('File', '/var/run/hadoop/hdfs/hadoop-hdfs-namenode.pid', action=['delete'], not_if='ls /var/run/hadoop/hdfs/hadoop-hdfs-namenode.pid >/dev/null 2>&1 && ps -p `cat /var/run/hadoop/hdfs/hadoop-hdfs-namenode.pid` >/dev/null 2>&1')
    self.assertResourceCalled('Execute', "/usr/bin/sudo su hdfs -l -s /bin/bash -c '[RMF_EXPORT_PLACEHOLDER]ulimit -c unlimited &&  /usr/lib/hadoop/sbin/hadoop-daemon.sh --config /etc/hadoop/conf start namenode'", environment={'HADOOP_LIBEXEC_DIR': '/usr/lib/hadoop/libexec', }, not_if='ls /var/run/hadoop/hdfs/hadoop-hdfs-namenode.pid >/dev/null 2>&1 && ps -p `cat /var/run/hadoop/hdfs/hadoop-hdfs-namenode.pid` >/dev/null 2>&1')
    self.assertResourceCalled('Execute', 'hdfs --config /etc/hadoop/conf dfsadmin -safemode leave', path=['/usr/bin'], user='hdfs')
    self.assertResourceCalled('Execute', "hadoop dfsadmin -safemode get | grep 'Safe mode is OFF'", path=['/usr/bin'], tries=40, only_if=None, user='hdfs', try_sleep=10)
    self.assertResourceCalled('HdfsResource', '/tmp', security_enabled=False, hadoop_conf_dir='/etc/hadoop/conf', keytab=UnknownConfigurationMock(), hadoop_fs='hdfs://c6401.ambari.apache.org:8020', kinit_path_local='/usr/bin/kinit', user='hdfs', owner='hdfs', hadoop_bin_dir='/usr/bin', type='directory', action=['create_delayed'], mode=511)
    self.assertResourceCalled('HdfsResource', '/user/ambari-qa', security_enabled=False, hadoop_conf_dir='/etc/hadoop/conf', keytab=UnknownConfigurationMock(), hadoop_fs='hdfs://c6401.ambari.apache.org:8020', kinit_path_local='/usr/bin/kinit', user='hdfs', owner='ambari-qa', hadoop_bin_dir='/usr/bin', type='directory', action=['create_delayed'], mode=504)
    self.assertResourceCalled('HdfsResource', None, security_enabled=False, hadoop_bin_dir='/usr/bin', keytab=UnknownConfigurationMock(), hadoop_fs='hdfs://c6401.ambari.apache.org:8020', kinit_path_local='/usr/bin/kinit', user='hdfs', action=['execute'], hadoop_conf_dir='/etc/hadoop/conf', only_if=None)
    self.assertNoMoreResources()
