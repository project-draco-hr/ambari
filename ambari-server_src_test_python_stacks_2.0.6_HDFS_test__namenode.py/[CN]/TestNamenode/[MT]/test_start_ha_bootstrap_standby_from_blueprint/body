@patch.object(shell, 'call')
def test_start_ha_bootstrap_standby_from_blueprint(self, call_mocks):
    call_mocks = MagicMock(return_value=(0, ''))
    self.executeScript((self.COMMON_SERVICES_PACKAGE_DIR + '/scripts/namenode.py'), classname='NameNode', command='start', config_file='ha_bootstrap_standby_node.json', stack_version=self.STACK_VERSION, target=RMFTestCase.TARGET_COMMON_SERVICES, call_mocks=call_mocks)
    self.assert_configure_default()
    self.assertResourceCalled('File', '/etc/hadoop/conf/dfs.exclude', owner='hdfs', content=Template('exclude_hosts_list.j2'), group='hadoop')
    self.assertResourceCalled('Directory', '/hadoop/hdfs/namenode/namenode-bootstrapped/', create_parents=True)
    self.assertResourceCalled('Directory', '/var/run/hadoop', owner='hdfs', group='hadoop', mode=493)
    self.assertResourceCalled('Directory', '/var/run/hadoop/hdfs', owner='hdfs', group='hadoop', create_parents=True)
    self.assertResourceCalled('Directory', '/var/log/hadoop/hdfs', owner='hdfs', group='hadoop', create_parents=True)
    self.assertResourceCalled('File', '/var/run/hadoop/hdfs/hadoop-hdfs-namenode.pid', action=['delete'], not_if='ambari-sudo.sh [RMF_ENV_PLACEHOLDER] -H -E test -f /var/run/hadoop/hdfs/hadoop-hdfs-namenode.pid && ambari-sudo.sh [RMF_ENV_PLACEHOLDER] -H -E pgrep -F /var/run/hadoop/hdfs/hadoop-hdfs-namenode.pid')
    self.assertResourceCalled('Execute', "ambari-sudo.sh su hdfs -l -s /bin/bash -c '[RMF_EXPORT_PLACEHOLDER]ulimit -c unlimited ;  /usr/lib/hadoop/sbin/hadoop-daemon.sh --config /etc/hadoop/conf start namenode'", environment={'HADOOP_LIBEXEC_DIR': '/usr/lib/hadoop/libexec', }, not_if='ambari-sudo.sh [RMF_ENV_PLACEHOLDER] -H -E test -f /var/run/hadoop/hdfs/hadoop-hdfs-namenode.pid && ambari-sudo.sh [RMF_ENV_PLACEHOLDER] -H -E pgrep -F /var/run/hadoop/hdfs/hadoop-hdfs-namenode.pid')
    self.assertResourceCalled('Execute', "hdfs dfsadmin -fs hdfs://c6402.ambari.apache.org:8020 -safemode get | grep 'Safe mode is OFF'", tries=115, try_sleep=10, user='hdfs', logoutput=True)
    self.assertResourceCalled('HdfsResource', '/tmp', immutable_paths=self.DEFAULT_IMMUTABLE_PATHS, security_enabled=False, only_if="ambari-sudo.sh su hdfs -l -s /bin/bash -c 'export  PATH=/bin:/usr/bin ; hdfs --config /etc/hadoop/conf haadmin -ns ns1 -getServiceState nn2 | grep active'", keytab=UnknownConfigurationMock(), hadoop_bin_dir='/usr/bin', default_fs='hdfs://ns1', hdfs_site=self.getConfig()['configurations']['hdfs-site'], kinit_path_local='/usr/bin/kinit', principal_name=None, user='hdfs', dfs_type='', owner='hdfs', hadoop_conf_dir='/etc/hadoop/conf', type='directory', action=['create_on_execute'], hdfs_resource_ignore_file='/var/lib/ambari-agent/data/.hdfs_resource_ignore', mode=511)
    self.assertResourceCalled('HdfsResource', '/user/ambari-qa', immutable_paths=self.DEFAULT_IMMUTABLE_PATHS, security_enabled=False, only_if="ambari-sudo.sh su hdfs -l -s /bin/bash -c 'export  PATH=/bin:/usr/bin ; hdfs --config /etc/hadoop/conf haadmin -ns ns1 -getServiceState nn2 | grep active'", keytab=UnknownConfigurationMock(), hadoop_bin_dir='/usr/bin', default_fs='hdfs://ns1', hdfs_site=self.getConfig()['configurations']['hdfs-site'], kinit_path_local='/usr/bin/kinit', principal_name=None, user='hdfs', dfs_type='', owner='ambari-qa', hadoop_conf_dir='/etc/hadoop/conf', type='directory', action=['create_on_execute'], hdfs_resource_ignore_file='/var/lib/ambari-agent/data/.hdfs_resource_ignore', mode=504)
    self.assertResourceCalled('HdfsResource', None, immutable_paths=self.DEFAULT_IMMUTABLE_PATHS, security_enabled=False, only_if="ambari-sudo.sh su hdfs -l -s /bin/bash -c 'export  PATH=/bin:/usr/bin ; hdfs --config /etc/hadoop/conf haadmin -ns ns1 -getServiceState nn2 | grep active'", keytab=UnknownConfigurationMock(), hadoop_bin_dir='/usr/bin', default_fs='hdfs://ns1', hdfs_site=self.getConfig()['configurations']['hdfs-site'], kinit_path_local='/usr/bin/kinit', principal_name=None, user='hdfs', dfs_type='', action=['execute'], hdfs_resource_ignore_file='/var/lib/ambari-agent/data/.hdfs_resource_ignore', hadoop_conf_dir='/etc/hadoop/conf')
    self.assertNoMoreResources()
    self.assertTrue(call_mocks.called)
    self.assertEqual(2, call_mocks.call_count)
    calls = [call('hdfs namenode -bootstrapStandby -nonInteractive', logoutput=False, user=u'hdfs'), call("ambari-sudo.sh su hdfs -l -s /bin/bash -c 'export  PATH=/bin:/usr/bin ; hdfs --config /etc/hadoop/conf haadmin -ns ns1 -getServiceState nn2 | grep active'")]
    call_mocks.assert_has_calls(calls, any_order=False)
