def test_start_ha_default(self):
    self.executeScript('2.0.6/services/HDFS/package/scripts/namenode.py', classname='NameNode', command='start', config_file='ha_default.json')
    self.assert_configure_default()
    self.assertResourceCalled('File', '/etc/hadoop/conf/dfs.exclude', owner='hdfs', content=Template('exclude_hosts_list.j2'), group='hadoop')
    self.assertResourceCalled('Directory', '/var/run/hadoop/hdfs', owner='hdfs', recursive=True)
    self.assertResourceCalled('Directory', '/var/log/hadoop/hdfs', owner='hdfs', recursive=True)
    self.assertResourceCalled('File', '/var/run/hadoop/hdfs/hadoop-hdfs-namenode.pid', action=['delete'], ignore_failures=True, not_if='ls /var/run/hadoop/hdfs/hadoop-hdfs-namenode.pid >/dev/null 2>&1 && ps `cat /var/run/hadoop/hdfs/hadoop-hdfs-namenode.pid` >/dev/null 2>&1')
    self.assertResourceCalled('Execute', 'ulimit -c unlimited;  export HADOOP_LIBEXEC_DIR=/usr/lib/hadoop/libexec && /usr/lib/hadoop/sbin/hadoop-daemon.sh --config /etc/hadoop/conf start namenode', not_if='ls /var/run/hadoop/hdfs/hadoop-hdfs-namenode.pid >/dev/null 2>&1 && ps `cat /var/run/hadoop/hdfs/hadoop-hdfs-namenode.pid` >/dev/null 2>&1', user='hdfs')
    self.assertResourceCalled('Execute', "su - hdfs -c 'hadoop dfsadmin -safemode get' | grep 'Safe mode is OFF'", tries=40, only_if="su - hdfs -c 'hdfs haadmin -getServiceState nn1 | grep active > /dev/null'", try_sleep=10)
    self.assertResourceCalled('HdfsDirectory', '/tmp', security_enabled=False, keytab=UnknownConfigurationMock(), conf_dir='/etc/hadoop/conf', hdfs_user='hdfs', kinit_path_local='/usr/bin/kinit', mode=511, owner='hdfs', action=['create_delayed'])
    self.assertResourceCalled('HdfsDirectory', '/user/ambari-qa', security_enabled=False, keytab=UnknownConfigurationMock(), conf_dir='/etc/hadoop/conf', hdfs_user='hdfs', kinit_path_local='/usr/bin/kinit', mode=504, owner='ambari-qa', action=['create_delayed'])
    self.assertResourceCalled('HdfsDirectory', None, security_enabled=False, keytab=UnknownConfigurationMock(), conf_dir='/etc/hadoop/conf', hdfs_user='hdfs', kinit_path_local='/usr/bin/kinit', action=['create'], only_if="su - hdfs -c 'hdfs haadmin -getServiceState nn1 | grep active > /dev/null'")
    self.assertNoMoreResources()
