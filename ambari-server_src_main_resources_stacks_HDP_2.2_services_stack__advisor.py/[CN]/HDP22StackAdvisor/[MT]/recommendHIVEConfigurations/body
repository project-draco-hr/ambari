def recommendHIVEConfigurations(self, configurations, clusterData, services, hosts):
    super(HDP22StackAdvisor, self).recommendHiveConfigurations(configurations, clusterData, services, hosts)
    putHiveServerProperty = self.putProperty(configurations, 'hiveserver2-site', services)
    putHiveEnvProperty = self.putProperty(configurations, 'hive-env', services)
    putHiveSiteProperty = self.putProperty(configurations, 'hive-site', services)
    putHiveSitePropertyAttribute = self.putPropertyAttribute(configurations, 'hive-site')
    servicesList = [service['StackServices']['service_name'] for service in services['services']]
    if (('ranger-hive-plugin-properties' in services['configurations']) and ('ranger-hive-plugin-enabled' in services['configurations']['ranger-hive-plugin-properties']['properties'])):
        rangerPluginEnabled = services['configurations']['ranger-hive-plugin-properties']['properties']['ranger-hive-plugin-enabled']
        if ('RANGER' in servicesList):
            if (rangerPluginEnabled.lower() == 'Yes'.lower()):
                putHiveServerProperty('hive.security.authorization.manager', 'com.xasecure.authorization.hive.authorizer.XaSecureHiveAuthorizerFactory')
                putHiveServerProperty('hive.security.authenticator.manager', 'org.apache.hadoop.hive.ql.security.SessionStateUserAuthenticator')
            elif (rangerPluginEnabled.lower() == 'No'.lower()):
                putHiveServerProperty('hive.security.authorization.manager', 'org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactory')
                putHiveServerProperty('hive.security.authenticator.manager', 'org.apache.hadoop.hive.ql.security.SessionStateUserAuthenticator')
    putHiveEnvProperty('hive_exec_orc_storage_strategy', 'SPEED')
    putHiveSiteProperty('hive.exec.orc.encoding.strategy', configurations['hive-env']['properties']['hive_exec_orc_storage_strategy'])
    putHiveSiteProperty('hive.exec.orc.compression.strategy', configurations['hive-env']['properties']['hive_exec_orc_storage_strategy'])
    putHiveSiteProperty('hive.exec.orc.default.stripe.size', '67108864')
    putHiveSiteProperty('hive.exec.orc.default.compress', 'ZLIB')
    putHiveSiteProperty('hive.optimize.index.filter', 'true')
    putHiveSiteProperty('hive.optimize.sort.dynamic.partition', 'false')
    putHiveSiteProperty('hive.vectorized.execution.enabled', 'true')
    putHiveSiteProperty('hive.vectorized.execution.reduce.enabled', 'false')
    putHiveEnvProperty('hive_txn_acid', 'off')
    if (str(configurations['hive-env']['properties']['hive_txn_acid']).lower() == 'on'):
        putHiveSiteProperty('hive.txn.manager', 'org.apache.hadoop.hive.ql.lockmgr.DbTxnManager')
        putHiveSiteProperty('hive.support.concurrency', 'true')
        putHiveSiteProperty('hive.compactor.initiator.on', 'true')
        putHiveSiteProperty('hive.compactor.worker.threads', '1')
        putHiveSiteProperty('hive.enforce.bucketing', 'true')
        putHiveSiteProperty('hive.exec.dynamic.partition.mode', 'nonstrict')
    else:
        putHiveSiteProperty('hive.txn.manager', 'org.apache.hadoop.hive.ql.lockmgr.DummyTxnManager')
        putHiveSiteProperty('hive.support.concurrency', 'false')
        putHiveSiteProperty('hive.compactor.initiator.on', 'false')
        putHiveSiteProperty('hive.compactor.worker.threads', '0')
        putHiveSiteProperty('hive.enforce.bucketing', 'false')
        putHiveSiteProperty('hive.exec.dynamic.partition.mode', 'strict')
    putHiveEnvProperty('hive_timeline_logging_enabled', 'true')
    hooks_properties = ['hive.exec.pre.hooks', 'hive.exec.post.hooks', 'hive.exec.failure.hooks']
    include_ats_hook = (str(configurations['hive-env']['properties']['hive_timeline_logging_enabled']).lower() == 'true')
    ats_hook_class = 'org.apache.hadoop.hive.ql.hooks.ATSHook'
    for hooks_property in hooks_properties:
        if (hooks_property in configurations['hive-site']['properties']):
            hooks_value = configurations['hive-site']['properties'][hooks_property]
        else:
            hooks_value = ' '
        if (include_ats_hook and (ats_hook_class not in hooks_value)):
            if (hooks_value == ' '):
                hooks_value = ats_hook_class
            else:
                hooks_value = ((hooks_value + ',') + ats_hook_class)
        if ((not include_ats_hook) and (ats_hook_class in hooks_value)):
            hooks_classes = []
            for hook_class in hooks_value.split(','):
                if ((hook_class != ats_hook_class) and (hook_class != ' ')):
                    hooks_classes.append(hook_class)
            if hooks_classes:
                hooks_value = ','.join(hooks_classes)
            else:
                hooks_value = ' '
        putHiveSiteProperty(hooks_property, hooks_value)
    if ('TEZ' in servicesList):
        putHiveSiteProperty('hive.execution.engine', 'tez')
    else:
        putHiveSiteProperty('hive.execution.engine', 'mr')
    container_size = '512'
    if (not ('yarn-site' in configurations)):
        self.recommendYARNConfigurations(configurations, clusterData, services, hosts)
    yarnMaxAllocationSize = min((30 * int(configurations['yarn-site']['properties']['yarn.scheduler.minimum-allocation-mb'])), int(configurations['yarn-site']['properties']['yarn.scheduler.maximum-allocation-mb']))
    container_size = (clusterData['mapMemory'] if (clusterData['mapMemory'] > 2048) else int(clusterData['reduceMemory']))
    container_size = min((clusterData['containers'] * clusterData['ramPerContainer']), container_size, yarnMaxAllocationSize)
    putHiveSiteProperty('hive.tez.container.size', container_size)
    putHiveSiteProperty('hive.prewarm.enabled', 'false')
    putHiveSiteProperty('hive.prewarm.numcontainers', '3')
    putHiveSiteProperty('hive.tez.auto.reducer.parallelism', 'true')
    putHiveSiteProperty('hive.tez.dynamic.partition.pruning', 'true')
    container_size = configurations['hive-site']['properties']['hive.tez.container.size']
    container_size_bytes = ((int(container_size) * 1024) * 1024)
    putHiveSiteProperty('hive.auto.convert.join.noconditionaltask.size', int((container_size_bytes / 3)))
    putHiveSitePropertyAttribute('hive.auto.convert.join.noconditionaltask.size', 'maximum', container_size_bytes)
    putHiveSiteProperty('hive.exec.reducers.bytes.per.reducer', '67108864')
    putHiveEnvProperty('cost_based_optimizer', 'On')
    if (str(configurations['hive-env']['properties']['cost_based_optimizer']).lower() == 'on'):
        putHiveSiteProperty('hive.cbo.enable', 'true')
    else:
        putHiveSiteProperty('hive.cbo.enable', 'false')
    hive_cbo_enable = configurations['hive-site']['properties']['hive.cbo.enable']
    putHiveSiteProperty('hive.stats.fetch.partition.stats', hive_cbo_enable)
    putHiveSiteProperty('hive.stats.fetch.column.stats', hive_cbo_enable)
    putHiveSiteProperty('hive.compute.query.using.stats', 'true')
    putHiveServerProperty('hive.server2.tez.initialize.default.sessions', 'false')
    putHiveServerProperty('hive.server2.tez.sessions.per.default.queue', '1')
    putHiveServerProperty('hive.server2.enable.doAs', 'true')
    putHiveServerProperty('tez.session.am.dag.submit.timeout.secs', '600')
    yarn_queues = 'default'
    if (('capacity-scheduler' in configurations) and ('yarn.scheduler.capacity.root.queues' in configurations['capacity-scheduler']['properties'])):
        yarn_queues = str(configurations['capacity-scheduler']['properties']['yarn.scheduler.capacity.root.queues'])
    putHiveServerProperty('hive.server2.tez.default.queues', yarn_queues)
    putHiveServerPropertyAttribute = self.putPropertyAttribute(configurations, 'hiveserver2-site')
    entries = []
    for queue in yarn_queues.split(','):
        entries.append({'label': (str(queue) + ' queue'), 'value': queue, })
    putHiveServerPropertyAttribute('hive.server2.tez.default.queues', 'entries', entries)
    putHiveEnvProperty('hive_security_authorization', 'None')
    if (str(configurations['hive-env']['properties']['hive_security_authorization']).lower() == 'none'):
        putHiveSiteProperty('hive.security.authorization.enabled', 'false')
    else:
        putHiveSiteProperty('hive.security.authorization.enabled', 'true')
    try:
        auth_manager_value = str(configurations['hive-env']['properties']['hive.security.metastore.authorization.manager'])
    except KeyError:
        auth_manager_value = ''
        pass
    sqlstdauth_class = 'org.apache.hadoop.hive.ql.security.authorization.MetaStoreAuthzAPIAuthorizerEmbedOnly'
    putHiveServerProperty('hive.server2.enable.doAs', 'true')
    if (str(configurations['hive-env']['properties']['hive_security_authorization']).lower() == 'sqlstdauth'):
        putHiveServerProperty('hive.server2.enable.doAs', 'false')
        if (sqlstdauth_class not in auth_manager_value):
            putHiveSiteProperty('hive.security.metastore.authorization.manager', ((auth_manager_value + ',') + sqlstdauth_class))
    elif (auth_manager_value != ''):
        auth_manager_values = auth_manager_value.split(',')
        auth_manager_values = [x for x in auth_manager_values if (x != sqlstdauth_class)]
        putHiveSiteProperty('hive.security.metastore.authorization.manager', ','.join(auth_manager_values))
        pass
    putHiveSiteProperty('hive.server2.use.SSL', 'false')
    hive_server2_auth = None
    if (('hive-site' in services['configurations']) and ('hive.server2.authentication' in services['configurations']['hive-site']['properties'])):
        hive_server2_auth = str(services['configurations']['hive-site']['properties']['hive.server2.authentication']).lower()
    elif ('hive.server2.authentication' in configurations['hive-site']['properties']):
        hive_server2_auth = str(configurations['hive-site']['properties']['hive.server2.authentication']).lower()
    if (hive_server2_auth == 'ldap'):
        putHiveSiteProperty('hive.server2.authentication.ldap.url', '')
        putHiveSiteProperty('hive.server2.authentication.ldap.baseDN', ' ')
    else:
        putHiveSitePropertyAttribute('hive.server2.authentication.ldap.url', 'delete', 'true')
        putHiveSitePropertyAttribute('hive.server2.authentication.ldap.baseDN', 'delete', 'true')
    if (hive_server2_auth == 'kerberos'):
        putHiveSiteProperty('hive.server2.authentication.kerberos.keytab', '')
        putHiveSiteProperty('hive.server2.authentication.kerberos.principal', '')
    else:
        putHiveSitePropertyAttribute('hive.server2.authentication.kerberos.keytab', 'delete', 'true')
        putHiveSitePropertyAttribute('hive.server2.authentication.kerberos.principal', 'delete', 'true')
    if (hive_server2_auth == 'pam'):
        putHiveSiteProperty('hive.server2.authentication.pam.services', '')
    else:
        putHiveSitePropertyAttribute('hive.server2.authentication.pam.services', 'delete', 'true')
    if (hive_server2_auth == 'custom'):
        putHiveSiteProperty('hive.server2.custom.authentication.class', '')
    else:
        putHiveSitePropertyAttribute('hive.server2.custom.authentication.class', 'delete', 'true')
