def __update_hdfs_client():
    '\n  Writes hdfs-client.xml on the local filesystem on hawq nodes.\n  If hdfs ha is enabled, appends related parameters to hdfs-client.xml\n  '
    import params
    hdfs_client_dict = params.hdfs_client.copy()
    dfs_nameservice = params.hdfs_site.get('dfs.nameservices')
    if dfs_nameservice:
        ha_namenodes = 'dfs.ha.namenodes.{0}'.format(dfs_nameservice)
        ha_nn_list = [ha_nn.strip() for ha_nn in params.hdfs_site[ha_namenodes].split(',')]
        required_keys = ('dfs.nameservices', ha_namenodes, 'dfs.namenode.rpc-address.{0}.{1}'.format(dfs_nameservice, ha_nn_list[0]), 'dfs.namenode.http-address.{0}.{1}'.format(dfs_nameservice, ha_nn_list[0]), 'dfs.namenode.rpc-address.{0}.{1}'.format(dfs_nameservice, ha_nn_list[1]), 'dfs.namenode.http-address.{0}.{1}'.format(dfs_nameservice, ha_nn_list[1]))
        for key in required_keys:
            hdfs_client_dict[key] = params.hdfs_site[key]
    if params.security_enabled:
        hdfs_client_dict['hadoop.security.authentication'] = 'kerberos'
    else:
        hdfs_client_dict.pop('hadoop.security.authentication', None)
    XmlConfig('hdfs-client.xml', conf_dir=hawq_constants.hawq_config_dir, configurations=ConfigDictionary(hdfs_client_dict), configuration_attributes=params.config['configuration_attributes']['hdfs-client'], owner=hawq_constants.hawq_user, group=hawq_constants.hawq_group, mode=420)
