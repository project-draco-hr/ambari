{
  HttpSession session=req.getSession(true);
  final Logger logger=Logger.getLogger(PigJobMigration.class);
  Connection connectionHuedb=null;
  Connection connectionAmbaridb=null;
  userName=req.getParameter("username");
  startDate=req.getParameter("startdate");
  endDate=req.getParameter("enddate");
  instance=req.getParameter("instance");
  logger.info("------------------------------");
  logger.info("Pig Jobs Migration started");
  logger.info("------------------------------");
  logger.info("start date: " + startDate);
  logger.info("enddate date: " + endDate);
  logger.info("instance is: " + userName);
  logger.info("hue username is : " + instance);
  PigJobImpl pigjobimpl=new PigJobImpl();
  int maxCountforPigScript=0;
  String time=null, timeIndorder=null;
  Long epochtime=null;
  String pigJobDirName;
  ArrayList<PojoPig> pigJobDbPojo=new ArrayList<PojoPig>();
  try {
    connectionHuedb=DataSourceHueDatabase.getInstance(view.getProperties().get("huedrivername"),view.getProperties().get("huejdbcurl"),view.getProperties().get("huedbusername"),view.getProperties().get("huedbpassword")).getConnection();
    pigJobDbPojo=pigjobimpl.fetchFromHueDB(userName,startDate,endDate,connectionHuedb);
    if (pigJobDbPojo.size() == 0) {
      logger.info("no Pig Job has been selected from hue according to your criteria of searching");
      resp.setContentType("text/html");
      PrintWriter out=resp.getWriter();
      out.println("<br>");
      out.println("<h4>No Pig Job  selected according to your criteria</h4>");
    }
 else {
      connectionAmbaridb=DataSourceAmbariDatabase.getInstance(view.getProperties().get("ambaridrivername"),view.getProperties().get("ambarijdbcurl"),view.getProperties().get("ambaridbusername"),view.getProperties().get("ambaridbpassword")).getConnection();
      connectionAmbaridb.setAutoCommit(false);
      for (i=0; i < pigJobDbPojo.size(); i++) {
        float calc=((float)(i + 1)) / pigJobDbPojo.size() * 100;
        int progressPercentage=Math.round(calc);
        session.setAttribute(ProgressBarStatus.TASK_PROGRESS_VARIABLE,progressPercentage);
        logger.info("Loop No." + (i + 1));
        logger.info("________________");
        logger.info("the title of script " + pigJobDbPojo.get(i).getTitle());
        int fetchPigTablenameInstance=pigjobimpl.fetchInstanceTablename(view.getProperties().get("ambaridrivername"),connectionAmbaridb,instance);
        maxCountforPigScript=(pigjobimpl.fetchMaxIdforPigJob(view.getProperties().get("ambaridrivername"),connectionAmbaridb,fetchPigTablenameInstance) + 1);
        time=pigjobimpl.getTime();
        timeIndorder=pigjobimpl.getTimeInorder();
        epochtime=pigjobimpl.getEpochTime();
        pigJobDirName="/user/admin/pig/jobs/" + pigJobDbPojo.get(i).getTitle() + "_"+ time+ "/";
        pigjobimpl.insertRowPigJob(view.getProperties().get("ambaridrivername"),pigJobDirName,maxCountforPigScript,time,timeIndorder,epochtime,pigJobDbPojo.get(i).getTitle(),connectionAmbaridb,fetchPigTablenameInstance,pigJobDbPojo.get(i).getStatus(),instance,i);
        if (view.getProperties().get("KerberoseEnabled").equals("y")) {
          pigjobimpl.createDirPigJobSecured(pigJobDirName,view.getProperties().get("namenode_URI_Ambari"));
          pigjobimpl.copyFileBetweenHdfsSecured(pigJobDbPojo.get(i).getDir() + "/script.pig",pigJobDirName,view.getProperties().get("namenode_URI_Ambari"),view.getProperties().get("namenode_URI_Hue"));
          pigjobimpl.copyFileBetweenHdfsSecured(pigJobDbPojo.get(i).getDir() + "/stderr",pigJobDirName,view.getProperties().get("namenode_URI_Ambari"),view.getProperties().get("namenode_URI_Hue"));
          pigjobimpl.copyFileBetweenHdfsSecured(pigJobDbPojo.get(i).getDir() + "/stdout",pigJobDirName,view.getProperties().get("namenode_URI_Ambari"),view.getProperties().get("namenode_URI_Hue"));
        }
 else {
          pigjobimpl.createDirPigJob(pigJobDirName,view.getProperties().get("namenode_URI_Ambari"));
          pigjobimpl.copyFileBetweenHdfs(pigJobDbPojo.get(i).getDir() + "/script.pig",pigJobDirName,view.getProperties().get("namenode_URI_Ambari"),view.getProperties().get("namenode_URI_Hue"));
          pigjobimpl.copyFileBetweenHdfs(pigJobDbPojo.get(i).getDir() + "/stderr",pigJobDirName,view.getProperties().get("namenode_URI_Ambari"),view.getProperties().get("namenode_URI_Hue"));
          pigjobimpl.copyFileBetweenHdfs(pigJobDbPojo.get(i).getDir() + "/stdout",pigJobDirName,view.getProperties().get("namenode_URI_Ambari"),view.getProperties().get("namenode_URI_Hue"));
        }
        logger.info(pigJobDbPojo.get(i).getTitle() + "has been migrated to Ambari");
      }
      connectionAmbaridb.commit();
    }
  }
 catch (  SQLException e) {
    logger.error("sql exception in ambari database:",e);
    try {
      connectionAmbaridb.rollback();
      logger.info("roll back done");
    }
 catch (    SQLException e1) {
      logger.error("roll back  exception:",e1);
    }
  }
catch (  ClassNotFoundException e2) {
    logger.error("class not found exception:",e2);
  }
catch (  ParseException e) {
    logger.error("ParseException: ",e);
  }
catch (  URISyntaxException e) {
    logger.error("URISyntaxException",e);
  }
catch (  PropertyVetoException e) {
    logger.error("PropertyVetoException",e);
  }
 finally {
    if (null != connectionAmbaridb)     try {
      connectionAmbaridb.close();
    }
 catch (    SQLException e) {
      logger.error("connection closing exception ",e);
    }
  }
  logger.info("------------------------------");
  logger.info("Pig Job Migration End");
  logger.info("------------------------------");
  session.setAttribute(ProgressBarStatus.TASK_PROGRESS_VARIABLE,0);
  resp.setContentType("text/html");
  PrintWriter out=resp.getWriter();
  out.println("<br>");
  out.println("<h4>" + i + " Pig jobs has been migrated to  "+ instance+ "</h4>");
}
