def test_start_secured(self):
    self.executeScript('2.0.6/services/HDFS/package/scripts/datanode.py', classname='DataNode', command='start', config_file='secured.json')
    self.assert_configure_secured()
    self.assertResourceCalled('Directory', '/var/run/hadoop/hdfs', owner='hdfs', recursive=True)
    self.assertResourceCalled('Directory', '/var/log/hadoop/hdfs', owner='hdfs', recursive=True)
    self.assertResourceCalled('Directory', '/etc/hadoop/conf.empty', recursive=True, owner='root', group='root')
    self.assertResourceCalled('Link', '/etc/hadoop/conf', to='/etc/hadoop/conf.empty', not_if='ls /etc/hadoop/conf')
    self.assertResourceCalled('File', os.path.join('/etc/hadoop/conf', 'hadoop-env.sh'), owner='root', content=InlineTemplate(self.getConfig()['configurations']['hadoop-env']['content']), replace=True)
    self.assertResourceCalled('File', '/var/run/hadoop/hdfs/hadoop-hdfs-datanode.pid', action=['delete'], not_if='ls /var/run/hadoop/hdfs/hadoop-hdfs-datanode.pid >/dev/null 2>&1 && ps -p `cat /var/run/hadoop/hdfs/hadoop-hdfs-datanode.pid` >/dev/null 2>&1')
    self.assertResourceCalled('Execute', "ulimit -c unlimited;  su -s /bin/bash - root -c 'export HADOOP_LIBEXEC_DIR=/usr/lib/hadoop/libexec && /usr/lib/hadoop/sbin/hadoop-daemon.sh --config /etc/hadoop/conf start datanode'", not_if='ls /var/run/hadoop/hdfs/hadoop-hdfs-datanode.pid >/dev/null 2>&1 && ps -p `cat /var/run/hadoop/hdfs/hadoop-hdfs-datanode.pid` >/dev/null 2>&1')
    self.assertNoMoreResources()
