def test_start_secured_HDP22_non_root_https_only(self):
    config_file = 'stacks/2.0.6/configs/secured.json'
    with open(config_file, 'r') as f:
        secured_json = json.load(f)
    secured_json['hostLevelParams']['stack_version'] = '2.2'
    secured_json['configurations']['hdfs-site']['dfs.http.policy'] = 'HTTPS_ONLY'
    secured_json['configurations']['hdfs-site']['dfs.datanode.address'] = '0.0.0.0:10000'
    secured_json['configurations']['hdfs-site']['dfs.datanode.https.address'] = '0.0.0.0:50000'
    self.executeScript('2.0.6/services/HDFS/package/scripts/datanode.py', classname='DataNode', command='start', config_dict=secured_json)
    self.assert_configure_secured()
    self.assertResourceCalled('Directory', '/var/run/hadoop/hdfs', owner='hdfs', recursive=True)
    self.assertResourceCalled('Directory', '/var/log/hadoop/hdfs', owner='hdfs', recursive=True)
    self.assertResourceCalled('Execute', 'sed -i \'s/export HADOOP_SECURE_DN_USER=.*/export HADOOP_SECURE_DN_USER=""/\' /etc/hadoop/conf/hadoop-env.sh', not_if='ls /var/run/hadoop/hdfs/hadoop-hdfs-datanode.pid >/dev/null 2>&1 && ps `cat /var/run/hadoop/hdfs/hadoop-hdfs-datanode.pid` >/dev/null 2>&1')
    self.assertResourceCalled('File', '/var/run/hadoop/hdfs/hadoop-hdfs-datanode.pid', action=['delete'], not_if='ls /var/run/hadoop/hdfs/hadoop-hdfs-datanode.pid >/dev/null 2>&1 && ps -p `cat /var/run/hadoop/hdfs/hadoop-hdfs-datanode.pid` >/dev/null 2>&1')
    self.assertResourceCalled('Execute', "ulimit -c unlimited;  su -s /bin/bash - hdfs -c 'export HADOOP_LIBEXEC_DIR=/usr/hdp/current/hadoop-client/libexec && /usr/hdp/current/hadoop-client/sbin/hadoop-daemon.sh --config /etc/hadoop/conf start datanode'", not_if='ls /var/run/hadoop/hdfs/hadoop-hdfs-datanode.pid >/dev/null 2>&1 && ps -p `cat /var/run/hadoop/hdfs/hadoop-hdfs-datanode.pid` >/dev/null 2>&1')
    self.assertNoMoreResources()
