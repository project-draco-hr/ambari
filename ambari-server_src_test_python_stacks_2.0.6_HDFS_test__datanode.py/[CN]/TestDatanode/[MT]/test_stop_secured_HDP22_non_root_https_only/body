@patch('os.path.exists', new=MagicMock(return_value=False))
def test_stop_secured_HDP22_non_root_https_only(self):
    config_file = 'stacks/2.0.6/configs/secured.json'
    with open(config_file, 'r') as f:
        secured_json = json.load(f)
    secured_json['hostLevelParams']['stack_version'] = '2.2'
    secured_json['configurations']['hdfs-site']['dfs.http.policy'] = 'HTTPS_ONLY'
    secured_json['configurations']['hdfs-site']['dfs.datanode.address'] = '0.0.0.0:10000'
    secured_json['configurations']['hdfs-site']['dfs.datanode.https.address'] = '0.0.0.0:50000'
    self.executeScript('2.0.6/services/HDFS/package/scripts/datanode.py', classname='DataNode', command='stop', config_dict=secured_json)
    self.assertResourceCalled('Directory', '/var/run/hadoop/hdfs', owner='hdfs', recursive=True)
    self.assertResourceCalled('Directory', '/var/log/hadoop/hdfs', owner='hdfs', recursive=True)
    self.assertResourceCalled('File', '/var/run/hadoop/hdfs/hadoop-hdfs-datanode.pid', action=['delete'], not_if='ls /var/run/hadoop/hdfs/hadoop-hdfs-datanode.pid >/dev/null 2>&1 && ps `cat /var/run/hadoop/hdfs/hadoop-hdfs-datanode.pid` >/dev/null 2>&1')
    self.assertResourceCalled('Execute', "ulimit -c unlimited;  su -s /bin/bash - hdfs -c 'export HADOOP_LIBEXEC_DIR=/usr/lib/hadoop/libexec && /usr/lib/hadoop/sbin/hadoop-daemon.sh --config /etc/hadoop/conf stop datanode'", not_if=None)
    self.assertResourceCalled('File', '/var/run/hadoop/hdfs/hadoop-hdfs-datanode.pid', action=['delete'])
    self.assertNoMoreResources()
