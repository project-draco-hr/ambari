{
  Injector injector=Guice.createInjector(Modules.override(new InMemoryDefaultTestModule()).with(new MockModule()));
  injector.getInstance(GuiceJpaInitializer.class);
  injector.getInstance(EntityManager.class);
  long clusterId=injector.getInstance(OrmTestHelper.class).createCluster("cluster" + System.currentTimeMillis());
  Class<?> c=metaInfo.getClass().getSuperclass();
  Field f=c.getDeclaredField("alertDefinitionDao");
  f.setAccessible(true);
  f.set(metaInfo,injector.getInstance(AlertDefinitionDAO.class));
  f=c.getDeclaredField("ambariServiceAlertDefinitions");
  f.setAccessible(true);
  f.set(metaInfo,injector.getInstance(AmbariServiceAlertDefinitions.class));
  Clusters clusters=injector.getInstance(Clusters.class);
  Cluster cluster=clusters.getClusterById(clusterId);
  cluster.setDesiredStackVersion(new StackId(STACK_NAME_HDP,"2.0.6"));
  cluster.addService("HDFS");
  metaInfo.reconcileAlertDefinitions(clusters);
  AlertDefinitionDAO dao=injector.getInstance(AlertDefinitionDAO.class);
  List<AlertDefinitionEntity> definitions=dao.findAll(clusterId);
  assertEquals(11,definitions.size());
  int hostAlertCount=0;
  for (  AlertDefinitionEntity definition : definitions) {
    if (definition.getServiceName().equals("AMBARI") && definition.getComponentName().equals("AMBARI_AGENT")) {
      hostAlertCount++;
    }
  }
  assertEquals(2,hostAlertCount);
  assertEquals(9,definitions.size() - hostAlertCount);
  for (  AlertDefinitionEntity definition : definitions) {
    definition.setScheduleInterval(28);
    dao.merge(definition);
  }
  metaInfo.reconcileAlertDefinitions(clusters);
  definitions=dao.findAll();
  assertEquals(11,definitions.size());
  for (  AlertDefinitionEntity definition : definitions) {
    assertEquals(28,definition.getScheduleInterval().intValue());
  }
  definitions=dao.findAllEnabled(cluster.getClusterId());
  assertEquals(10,definitions.size());
  AlertDefinitionEntity entity=new AlertDefinitionEntity();
  entity.setClusterId(clusterId);
  entity.setDefinitionName("bad_hdfs_alert");
  entity.setLabel("Bad HDFS Alert");
  entity.setDescription("A way to fake a component being removed");
  entity.setEnabled(true);
  entity.setHash(UUID.randomUUID().toString());
  entity.setScheduleInterval(1);
  entity.setServiceName("HDFS");
  entity.setComponentName("BAD_COMPONENT");
  entity.setSourceType(SourceType.METRIC);
  entity.setSource("{\"type\" : \"METRIC\"}");
  dao.create(entity);
  definitions=dao.findAllEnabled(cluster.getClusterId());
  assertEquals(11,definitions.size());
  metaInfo.reconcileAlertDefinitions(clusters);
  definitions=dao.findAllEnabled(cluster.getClusterId());
  assertEquals(10,definitions.size());
  definitions=dao.findAll();
  assertEquals(12,definitions.size());
  entity=dao.findById(entity.getDefinitionId());
  assertFalse(entity.getEnabled());
}
