@OsFamilyFuncImpl(os_family=OsFamilyImpl.DEFAULT)
def namenode(action=None, do_format=True, rolling_restart=False, env=None):
    if (action == 'configure'):
        import params
        create_name_dirs(params.dfs_name_dir)
    elif (action == 'start'):
        setup_ranger_hdfs(rolling_upgrade=rolling_restart)
        import params
        if do_format:
            format_namenode()
            pass
        File(params.exclude_file_path, content=Template('exclude_hosts_list.j2'), owner=params.hdfs_user, group=params.user_group)
        if (params.dfs_ha_enabled and (params.dfs_ha_namenode_standby is not None) and (params.hostname == params.dfs_ha_namenode_standby)):
            success = bootstrap_standby_namenode(params)
            if (not success):
                raise Fail('Could not bootstrap standby namenode')
        options = ('-rollingUpgrade started' if rolling_restart else '')
        if rolling_restart:
            safe_zkfc_op(action, env)
        service(action='start', name='namenode', user=params.hdfs_user, options=options, create_pid_dir=True, create_log_dir=True)
        if params.security_enabled:
            Execute(format('{kinit_path_local} -kt {hdfs_user_keytab} {hdfs_principal_name}'), user=params.hdfs_user)
        is_namenode_safe_mode_off = format("hadoop dfsadmin -fs {namenode_address} -safemode get | grep 'Safe mode is OFF'")
        if params.dfs_ha_enabled:
            is_active_namenode_cmd = as_user(format('hdfs --config {hadoop_conf_dir} haadmin -getServiceState {namenode_id} | grep active'), params.hdfs_user, env={'PATH': params.hadoop_bin_dir, })
        else:
            is_active_namenode_cmd = None
        leave_safe_mode = False
        msg = ''
        if params.dfs_ha_enabled:
            (code, out) = shell.call(is_active_namenode_cmd, logoutput=True)
            if (code == 0):
                leave_safe_mode = True
                msg = 'Must leave safemode since High Availability is enabled and this is the Active NameNode.'
            elif rolling_restart:
                leave_safe_mode = True
                msg = 'Must leave safemode since High Availability is enabled during a Rolling Upgrade'
        else:
            msg = 'Must leave safemode since High Availability is not enabled.'
            leave_safe_mode = True
        if (not msg):
            msg = 'Will remain in the current safemode state.'
        Logger.info(msg)
        if leave_safe_mode:
            Logger.info('Checking the NameNode safemode status since may need to transition from ON to OFF.')
            (code, out) = shell.call(is_namenode_safe_mode_off, user=params.hdfs_user)
            if (code != 0):
                Logger.info('Will need to leave safemode, state should be OFF.')
                leave_safe_mode_cmd = format('hdfs --config {hadoop_conf_dir} dfsadmin -fs {namenode_address} -safemode leave')
                Execute(leave_safe_mode_cmd, tries=10, try_sleep=10, user=params.hdfs_user, path=[params.hadoop_bin_dir])
                Logger.info('Checking if safemode state is now OFF.')
                Execute(is_namenode_safe_mode_off, tries=40, try_sleep=10, path=[params.hadoop_bin_dir], user=params.hdfs_user)
                pass
            pass
        create_hdfs_directories(is_active_namenode_cmd)
    elif (action == 'stop'):
        import params
        service(action='stop', name='namenode', user=params.hdfs_user)
    elif (action == 'status'):
        import status_params
        check_process_status(status_params.namenode_pid_file)
    elif (action == 'decommission'):
        decommission()
