{
  final String expectedNameService="mynameservice";
  final String expectedHostName="serverThree";
  final String expectedHostNameTwo="serverFour";
  final String expectedPortNum="808080";
  final String expectedNodeOne="nn1";
  final String expectedNodeTwo="nn2";
  final String expectedHostGroupName="host_group_1";
  EasyMockSupport mockSupport=new EasyMockSupport();
  HostGroup mockHostGroupOne=mockSupport.createMock(HostGroup.class);
  expect(mockHostGroupOne.getHostInfo()).andReturn(Arrays.asList(expectedHostName,expectedHostNameTwo)).atLeastOnce();
  mockSupport.replayAll();
  Map<String,Map<String,String>> configProperties=new HashMap<String,Map<String,String>>();
  Map<String,String> hdfsSiteProperties=new HashMap<String,String>();
  Map<String,String> hadoopEnvProperties=new HashMap<String,String>();
  configProperties.put("hdfs-site",hdfsSiteProperties);
  configProperties.put("hadoop-env",hadoopEnvProperties);
  hdfsSiteProperties.put("dfs.nameservices",expectedNameService);
  hdfsSiteProperties.put("dfs.ha.namenodes.mynameservice",expectedNodeOne + ", " + expectedNodeTwo);
  hdfsSiteProperties.put("dfs.namenode.https-address." + expectedNameService + "."+ expectedNodeOne,createExportedAddress(expectedPortNum,expectedHostGroupName));
  hdfsSiteProperties.put("dfs.namenode.https-address." + expectedNameService + "."+ expectedNodeTwo,createExportedAddress(expectedPortNum,expectedHostGroupName));
  hdfsSiteProperties.put("dfs.namenode.http-address." + expectedNameService + "."+ expectedNodeOne,createExportedAddress(expectedPortNum,expectedHostGroupName));
  hdfsSiteProperties.put("dfs.namenode.http-address." + expectedNameService + "."+ expectedNodeTwo,createExportedAddress(expectedPortNum,expectedHostGroupName));
  hdfsSiteProperties.put("dfs.namenode.rpc-address." + expectedNameService + "."+ expectedNodeOne,createExportedAddress(expectedPortNum,expectedHostGroupName));
  hdfsSiteProperties.put("dfs.namenode.rpc-address." + expectedNameService + "."+ expectedNodeTwo,createExportedAddress(expectedPortNum,expectedHostGroupName));
  hadoopEnvProperties.put("dfs_ha_initial_namenode_active",expectedHostName);
  hadoopEnvProperties.put("dfs_ha_initial_namenode_standby",expectedHostNameTwo);
  BlueprintConfigurationProcessor configProcessor=new BlueprintConfigurationProcessor(configProperties);
  Map<String,HostGroup> mapOfHostGroups=new HashMap<String,HostGroup>();
  mapOfHostGroups.put(expectedHostGroupName,mockHostGroupOne);
  configProcessor.doUpdateForClusterCreate(mapOfHostGroups,null);
  assertEquals("HTTPS address HA property not properly exported",expectedHostName + ":" + expectedPortNum,hdfsSiteProperties.get("dfs.namenode.https-address." + expectedNameService + "."+ expectedNodeOne));
  assertEquals("HTTPS address HA property not properly exported",expectedHostName + ":" + expectedPortNum,hdfsSiteProperties.get("dfs.namenode.https-address." + expectedNameService + "."+ expectedNodeTwo));
  assertEquals("HTTPS address HA property not properly exported",expectedHostName + ":" + expectedPortNum,hdfsSiteProperties.get("dfs.namenode.http-address." + expectedNameService + "."+ expectedNodeOne));
  assertEquals("HTTPS address HA property not properly exported",expectedHostName + ":" + expectedPortNum,hdfsSiteProperties.get("dfs.namenode.http-address." + expectedNameService + "."+ expectedNodeTwo));
  assertEquals("HTTPS address HA property not properly exported",expectedHostName + ":" + expectedPortNum,hdfsSiteProperties.get("dfs.namenode.rpc-address." + expectedNameService + "."+ expectedNodeOne));
  assertEquals("HTTPS address HA property not properly exported",expectedHostName + ":" + expectedPortNum,hdfsSiteProperties.get("dfs.namenode.rpc-address." + expectedNameService + "."+ expectedNodeTwo));
  assertEquals("Active Namenode hostname was not set correctly",expectedHostName,hadoopEnvProperties.get("dfs_ha_initial_namenode_active"));
  assertEquals("Standby Namenode hostname was not set correctly",expectedHostNameTwo,hadoopEnvProperties.get("dfs_ha_initial_namenode_standby"));
  mockSupport.verifyAll();
}
