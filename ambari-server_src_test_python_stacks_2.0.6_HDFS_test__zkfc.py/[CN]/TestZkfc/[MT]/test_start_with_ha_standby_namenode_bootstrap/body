def test_start_with_ha_standby_namenode_bootstrap(self):
    self.executeScript((self.COMMON_SERVICES_PACKAGE_DIR + '/scripts/zkfc_slave.py'), classname='ZkfcSlave', command='start', config_file='ha_bootstrap_standby_node.json', stack_version=self.STACK_VERSION, target=RMFTestCase.TARGET_COMMON_SERVICES)
    self.assertResourceCalled('Directory', '/usr/lib/hadoop/lib/native/Linux-i386-32', create_parents=True)
    self.assertResourceCalled('Directory', '/usr/lib/hadoop/lib/native/Linux-amd64-64', create_parents=True)
    self.assertResourceCalled('Link', '/usr/lib/hadoop/lib/native/Linux-i386-32/libsnappy.so', to='/usr/lib/hadoop/lib/libsnappy.so')
    self.assertResourceCalled('Link', '/usr/lib/hadoop/lib/native/Linux-amd64-64/libsnappy.so', to='/usr/lib/hadoop/lib64/libsnappy.so')
    self.assertResourceCalled('Directory', '/etc/security/limits.d', owner='root', group='root', create_parents=True)
    self.assertResourceCalled('File', '/etc/security/limits.d/hdfs.conf', content=Template('hdfs.conf.j2'), owner='root', group='root', mode=420)
    self.assertResourceCalled('XmlConfig', 'hdfs-site.xml', owner='hdfs', group='hadoop', conf_dir='/etc/hadoop/conf', configurations=self.getConfig()['configurations']['hdfs-site'], configuration_attributes=self.getConfig()['configuration_attributes']['hdfs-site'])
    self.assertResourceCalled('XmlConfig', 'core-site.xml', owner='hdfs', group='hadoop', conf_dir='/etc/hadoop/conf', configurations=self.getConfig()['configurations']['core-site'], configuration_attributes=self.getConfig()['configuration_attributes']['core-site'], mode=420)
    self.assertResourceCalled('File', '/etc/hadoop/conf/slaves', content=Template('slaves.j2'), owner='hdfs')
    self.assertResourceCalled('Directory', '/var/run/hadoop', owner='hdfs', group='hadoop', mode=493)
    self.assertResourceCalled('Directory', '/var/run/hadoop', owner='hdfs', group='hadoop', mode=493)
    self.assertResourceCalled('Directory', '/var/run/hadoop/hdfs', owner='hdfs', create_parents=True, group='hadoop')
    self.assertResourceCalled('Directory', '/var/log/hadoop/hdfs', owner='hdfs', group='hadoop', create_parents=True)
    self.assertResourceCalled('File', '/var/run/hadoop/hdfs/hadoop-hdfs-zkfc.pid', action=['delete'], not_if='ambari-sudo.sh [RMF_ENV_PLACEHOLDER] -H -E test -f /var/run/hadoop/hdfs/hadoop-hdfs-zkfc.pid && ambari-sudo.sh [RMF_ENV_PLACEHOLDER] -H -E pgrep -F /var/run/hadoop/hdfs/hadoop-hdfs-zkfc.pid')
    self.assertResourceCalled('Execute', "ambari-sudo.sh su hdfs -l -s /bin/bash -c '[RMF_EXPORT_PLACEHOLDER]ulimit -c unlimited ;  /usr/lib/hadoop/sbin/hadoop-daemon.sh --config /etc/hadoop/conf start zkfc'", environment={'HADOOP_LIBEXEC_DIR': '/usr/lib/hadoop/libexec', }, not_if='ambari-sudo.sh [RMF_ENV_PLACEHOLDER] -H -E test -f /var/run/hadoop/hdfs/hadoop-hdfs-zkfc.pid && ambari-sudo.sh [RMF_ENV_PLACEHOLDER] -H -E pgrep -F /var/run/hadoop/hdfs/hadoop-hdfs-zkfc.pid')
    self.assertNoMoreResources()
