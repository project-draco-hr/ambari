{
  Resource.Type type=Resource.Type.ClusterStackVersion;
  String clusterName="Cluster100";
  AmbariManagementController managementController=createMock(AmbariManagementController.class);
  StackId stackId=new StackId("HDP","2.0.1");
  StackEntity stackEntity=stackDAO.find(stackId.getStackName(),stackId.getStackVersion());
  Assert.assertNotNull(stackEntity);
  ResourceTypeEntity resourceTypeEntity=resourceTypeDAO.findById(ResourceType.CLUSTER.getId());
  if (resourceTypeEntity == null) {
    resourceTypeEntity=new ResourceTypeEntity();
    resourceTypeEntity.setId(ResourceType.CLUSTER.getId());
    resourceTypeEntity.setName(ResourceType.CLUSTER.name());
    resourceTypeEntity=resourceTypeDAO.merge(resourceTypeEntity);
  }
  ResourceEntity resourceEntity=new ResourceEntity();
  resourceEntity.setResourceType(resourceTypeEntity);
  final Host host1=createNiceMock("host1",Host.class);
  final Host host2=createNiceMock("host2",Host.class);
  expect(host1.getHostName()).andReturn("host1").anyTimes();
  expect(host2.getHostName()).andReturn("host2").anyTimes();
  replay(host1,host2);
  ServiceComponentHost sch=createMock(ServiceComponentHost.class);
  List<ServiceComponentHost> schs=Collections.singletonList(sch);
  Cluster cluster=createNiceMock(Cluster.class);
  cluster.setClusterName(clusterName);
  ArrayList<Host> hosts=new ArrayList<Host>(){
{
      add(host1);
      add(host2);
    }
  }
;
  Clusters clusters=createNiceMock(Clusters.class);
  expect(clusters.getCluster(anyObject(String.class))).andReturn(cluster);
  RepositoryVersionEntity repoVersion=new RepositoryVersionEntity();
  repoVersion.setOperatingSystems(OS_JSON);
  StackEntity newDesiredStack=stackDAO.find("HDP","2.0.1");
  repoVersion.setStack(newDesiredStack);
  final ServiceOsSpecific.Package hivePackage=new ServiceOsSpecific.Package();
  hivePackage.setName("hive");
  final ServiceOsSpecific.Package mysqlPackage=new ServiceOsSpecific.Package();
  mysqlPackage.setName("mysql");
  mysqlPackage.setSkipUpgrade(Boolean.TRUE);
  List<ServiceOsSpecific.Package> packages=new ArrayList<ServiceOsSpecific.Package>(){
{
      add(hivePackage);
      add(mysqlPackage);
    }
  }
;
  ActionManager actionManager=createNiceMock(ActionManager.class);
  RequestStatusResponse response=createNiceMock(RequestStatusResponse.class);
  ResourceProviderFactory resourceProviderFactory=createNiceMock(ResourceProviderFactory.class);
  ResourceProvider csvResourceProvider=createNiceMock(ClusterStackVersionResourceProvider.class);
  CommandReport report=createNiceMock(CommandReport.class);
  FinalizeUpgradeAction finalizeUpgradeAction=createNiceMock(FinalizeUpgradeAction.class);
  AbstractControllerResourceProvider.init(resourceProviderFactory);
  Map<String,Map<String,String>> hostConfigTags=new HashMap<String,Map<String,String>>();
  expect(configHelper.getEffectiveDesiredTags(anyObject(ClusterImpl.class),anyObject(String.class))).andReturn(hostConfigTags);
  expect(managementController.getClusters()).andReturn(clusters).anyTimes();
  expect(managementController.getAmbariMetaInfo()).andReturn(ambariMetaInfo).anyTimes();
  expect(managementController.getAuthName()).andReturn("admin").anyTimes();
  expect(managementController.getActionManager()).andReturn(actionManager).anyTimes();
  expect(managementController.getJdkResourceUrl()).andReturn("/JdkResourceUrl").anyTimes();
  expect(managementController.getPackagesForServiceHost(anyObject(ServiceInfo.class),(Map<String,String>)anyObject(List.class),anyObject(String.class))).andReturn(packages).anyTimes();
  expect(resourceProviderFactory.getHostResourceProvider(anyObject(Set.class),anyObject(Map.class),eq(managementController))).andReturn(csvResourceProvider).anyTimes();
  expect(cluster.getCurrentStackVersion()).andReturn(stackId);
  expect(cluster.getServiceComponentHosts(anyObject(String.class))).andReturn(schs).anyTimes();
  Capture<StackId> capturedStackId=new Capture<StackId>();
  cluster.setDesiredStackVersion(capture(capturedStackId));
  expectLastCall().once();
  expect(cluster.getHosts()).andReturn(hosts).anyTimes();
  expect(sch.getServiceName()).andReturn("HIVE").anyTimes();
  expect(repositoryVersionDAOMock.findByDisplayName(anyObject(String.class))).andReturn(repoVersion);
  expect(actionManager.getRequestTasks(anyLong())).andReturn(Collections.<HostRoleCommand>emptyList()).anyTimes();
  expect(finalizeUpgradeAction.execute(null)).andReturn(report);
  expect(report.getStdOut()).andReturn("Dummy stdout");
  expect(report.getStdErr()).andReturn("Dummy stderr");
  expect(report.getStatus()).andReturn("COMPLETED");
  replay(managementController,response,clusters,resourceProviderFactory,csvResourceProvider,cluster,repositoryVersionDAOMock,configHelper,sch,actionManager,finalizeUpgradeAction,report,stageFactory);
  ResourceProvider provider=AbstractControllerResourceProvider.getResourceProvider(type,PropertyHelper.getPropertyIds(type),PropertyHelper.getKeyPropertyIds(type),managementController);
  injector.injectMembers(provider);
  Field field=ClusterStackVersionResourceProvider.class.getDeclaredField("finalizeUpgradeAction");
  field.setAccessible(true);
  field.set(provider,finalizeUpgradeAction);
  Map<String,Object> properties=new LinkedHashMap<String,Object>();
  properties.put(ClusterStackVersionResourceProvider.CLUSTER_STACK_VERSION_CLUSTER_NAME_PROPERTY_ID,clusterName);
  properties.put(ClusterStackVersionResourceProvider.CLUSTER_STACK_VERSION_STATE_PROPERTY_ID,"CURRENT");
  properties.put(ClusterStackVersionResourceProvider.CLUSTER_STACK_VERSION_REPOSITORY_VERSION_PROPERTY_ID,"HDP-2.2.2.0-2561");
  Request request=PropertyHelper.getUpdateRequest(properties,null);
  SecurityContextHolder.getContext().setAuthentication(authentication);
  provider.updateResources(request,null);
  verify(managementController,response);
  Assert.assertEquals(capturedStackId.getValue(),new StackId(newDesiredStack.getStackName(),newDesiredStack.getStackVersion()));
}
