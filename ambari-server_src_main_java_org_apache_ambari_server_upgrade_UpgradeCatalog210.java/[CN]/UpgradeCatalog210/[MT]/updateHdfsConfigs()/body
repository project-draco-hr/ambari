{
  AmbariManagementController ambariManagementController=injector.getInstance(AmbariManagementController.class);
  Clusters clusters=ambariManagementController.getClusters();
  if (clusters != null) {
    Map<String,Cluster> clusterMap=clusters.getClusters();
    Map<String,String> prop=new HashMap<String,String>();
    String content=null;
    if (clusterMap != null && !clusterMap.isEmpty()) {
      for (      final Cluster cluster : clusterMap.values()) {
        content=null;
        if (cluster.getDesiredConfigByType("hadoop-env") != null) {
          content=cluster.getDesiredConfigByType("hadoop-env").getProperties().get("content");
        }
        if (content != null) {
          content+="\nexport HADOOP_NAMENODE_OPTS=\"${HADOOP_NAMENODE_OPTS} -Dorg.mortbay.jetty.Request.maxFormContentSize=-1\"";
          prop.put("content",content);
          updateConfigurationPropertiesForCluster(cluster,"hadoop-env",prop,true,false);
        }
        if (cluster.getDesiredConfigByType("hdfs-site") != null && !cluster.getHosts("HDFS","NAMENODE").isEmpty()) {
          URI nameNodeRpc=null;
          String hostName=cluster.getHosts("HDFS","NAMENODE").iterator().next();
          if (cluster.getDesiredConfigByType("core-site").getProperties() != null && cluster.getDesiredConfigByType("core-site").getProperties().get("fs.defaultFS") != null) {
            try {
              nameNodeRpc=new URI(cluster.getDesiredConfigByType("core-site").getProperties().get("fs.defaultFS"));
              Map<String,String> hdfsProp=new HashMap<String,String>();
              hdfsProp.put("dfs.namenode.rpc-address",hostName + ":" + nameNodeRpc.getPort());
              updateConfigurationPropertiesForCluster(cluster,"hdfs-site",hdfsProp,true,false);
            }
 catch (            URISyntaxException e) {
              e.printStackTrace();
            }
          }
        }
      }
    }
  }
}
