def recommendHIVEConfigurations(self, configurations, clusterData, services, hosts):
    super(HDPWIN22StackAdvisor, self).recommendHiveConfigurations(configurations, clusterData, services, hosts)
    putHiveServerProperty = self.putProperty(configurations, 'hiveserver2-site', services)
    putHiveEnvProperty = self.putProperty(configurations, 'hive-env', services)
    putHiveSiteProperty = self.putProperty(configurations, 'hive-site', services)
    servicesList = [service['StackServices']['service_name'] for service in services['services']]
    putHiveSiteProperty('datanucleus.autoCreateSchema', 'false')
    putHiveEnvProperty('hive_exec_orc_storage_strategy', 'SPEED')
    putHiveSiteProperty('hive.exec.orc.encoding.strategy', configurations['hive-env']['properties']['hive_exec_orc_storage_strategy'])
    putHiveSiteProperty('hive.exec.orc.compression.strategy', configurations['hive-env']['properties']['hive_exec_orc_storage_strategy'])
    putHiveSiteProperty('hive.exec.orc.default.stripe.size', '67108864')
    putHiveSiteProperty('hive.exec.orc.default.compress', 'ZLIB')
    putHiveSiteProperty('hive.optimize.index.filter', 'true')
    putHiveSiteProperty('hive.optimize.sort.dynamic.partition', 'false')
    putHiveSiteProperty('hive.vectorized.execution.enabled', 'true')
    putHiveSiteProperty('hive.vectorized.execution.reduce.enabled', 'false')
    putHiveSiteProperty('hive.auto.convert.join.noconditionaltask.size', '2147483648')
    putHiveSiteProperty('hive.exec.reducers.bytes.per.reducer', '67108864')
    putHiveEnvProperty('hive_txn_acid', 'Off')
    if (str(configurations['hive-env']['properties']['hive_txn_acid']).lower() == 'on'):
        putHiveSiteProperty('hive.txn.manager', 'org.apache.hadoop.hive.ql.lockmgr.DbTxnManager')
        putHiveSiteProperty('hive.support.concurrency', 'true')
        putHiveSiteProperty('hive.compactor.initiator.on', 'true')
        putHiveSiteProperty('hive.compactor.worker.threads', '1')
        putHiveSiteProperty('hive.enforce.bucketing', 'true')
        putHiveSiteProperty('hive.exec.dynamic.partition.mode', 'nonstrict')
    else:
        putHiveSiteProperty('hive.txn.manager', 'org.apache.hadoop.hive.ql.lockmgr.DummyTxnManager')
        putHiveSiteProperty('hive.support.concurrency', 'false')
        putHiveSiteProperty('hive.compactor.initiator.on', 'false')
        putHiveSiteProperty('hive.compactor.worker.threads', '0')
        putHiveSiteProperty('hive.enforce.bucketing', 'false')
        putHiveSiteProperty('hive.exec.dynamic.partition.mode', 'strict')
    putHiveEnvProperty('hive_timeline_logging_enabled', 'true')
    hooks_properties = ['hive.exec.pre.hooks', 'hive.exec.post.hooks', 'hive.exec.failure.hooks']
    include_ats_hook = (str(configurations['hive-env']['properties']['hive_timeline_logging_enabled']).lower() == 'true')
    ats_hook_class = 'org.apache.hadoop.hive.ql.hooks.ATSHook'
    for hooks_property in hooks_properties:
        if (hooks_property in configurations['hive-site']['properties']):
            hooks_value = configurations['hive-site']['properties'][hooks_property]
        else:
            hooks_value = ' '
        if (include_ats_hook and (ats_hook_class not in hooks_value)):
            if (hooks_value == ' '):
                hooks_value = ats_hook_class
            else:
                hooks_value = ((hooks_value + ',') + ats_hook_class)
        if ((not include_ats_hook) and (ats_hook_class in hooks_value)):
            hooks_classes = []
            for hook_class in hooks_value.split(','):
                if ((hook_class != ats_hook_class) and (hook_class != ' ')):
                    hooks_classes.append(hook_class)
            if hooks_classes:
                hooks_value = ','.join(hooks_classes)
            else:
                hooks_value = ' '
        putHiveSiteProperty(hooks_property, hooks_value)
    if ('TEZ' in servicesList):
        putHiveSiteProperty('hive.execution.engine', 'tez')
    else:
        putHiveSiteProperty('hive.execution.engine', 'mr')
    container_size = '512'
    if (not ('yarn-site' in configurations)):
        self.recommendYARNConfigurations(configurations, clusterData, services, hosts)
    if (('yarn-site' in configurations) and ('yarn.scheduler.minimum-allocation-mb' in configurations['yarn-site']['properties'])):
        container_size = configurations['yarn-site']['properties']['yarn.scheduler.minimum-allocation-mb']
    putHiveSiteProperty('hive.tez.container.size', container_size)
    putHiveSiteProperty('hive.prewarm.enabled', 'false')
    putHiveSiteProperty('hive.prewarm.numcontainers', '3')
    putHiveSiteProperty('hive.tez.auto.reducer.parallelism', 'true')
    putHiveSiteProperty('hive.tez.dynamic.partition.pruning', 'true')
    putHiveEnvProperty('cost_based_optimizer', 'On')
    if (str(configurations['hive-env']['properties']['cost_based_optimizer']).lower() == 'on'):
        putHiveSiteProperty('hive.cbo.enable', 'true')
        putHiveSiteProperty('hive.stats.fetch.partition.stats', 'true')
        putHiveSiteProperty('hive.stats.fetch.column.stats', 'true')
    else:
        putHiveSiteProperty('hive.cbo.enable', 'false')
        putHiveSiteProperty('hive.stats.fetch.partition.stats', 'false')
        putHiveSiteProperty('hive.stats.fetch.column.stats', 'false')
    putHiveSiteProperty('hive.compute.query.using.stats ', 'true')
    putHiveServerProperty('hive.server2.tez.initialize.default.sessions', 'false')
    putHiveServerProperty('hive.server2.tez.sessions.per.default.queue', '1')
    putHiveServerProperty('hive.server2.enable.doAs', 'true')
    putHiveServerProperty('tez.session.am.dag.submit.timeout.secs', '600')
    yarn_queues = 'default'
    if (('capacity-scheduler' in configurations) and ('yarn.scheduler.capacity.root.queues' in configurations['capacity-scheduler']['properties'])):
        yarn_queues = str(configurations['capacity-scheduler']['properties']['yarn.scheduler.capacity.root.queues'])
    putHiveServerProperty('hive.server2.tez.default.queues', yarn_queues)
    putHiveServerPropertyAttribute = self.putPropertyAttribute(configurations, 'hiveserver2-site')
    entries = []
    for queue in yarn_queues.split(','):
        entries.append({'label': (str(queue) + ' queue'), 'value': queue, })
    putHiveServerPropertyAttribute('hive.server2.tez.default.queues', 'entries', entries)
    putHiveEnvProperty('hive_security_authorization', 'None')
    if (str(configurations['hive-env']['properties']['hive_security_authorization']).lower() == 'none'):
        putHiveSiteProperty('hive.security.authorization.enabled', 'false')
    else:
        putHiveSiteProperty('hive.security.authorization.enabled', 'true')
    if (str(configurations['hive-env']['properties']['hive_security_authorization']).lower() == 'sqlstdauth'):
        auth_manager_value = str(configurations['hive-env']['properties']['hive.security.metastore.authorization.manager'])
        sqlstdauth_class = 'org.apache.hadoop.hive.ql.security.authorization.MetaStoreAuthzAPIAuthorizerEmbedOnly'
        if (sqlstdauth_class not in auth_manager_value):
            putHiveSiteProperty('hive.security.metastore.authorization.manager', ((auth_manager_value + ',') + sqlstdauth_class))
    putHiveServerProperty('hive.server2.enable.doAs', 'true')
    putHiveSiteProperty('hive.server2.use.SSL', 'false')
