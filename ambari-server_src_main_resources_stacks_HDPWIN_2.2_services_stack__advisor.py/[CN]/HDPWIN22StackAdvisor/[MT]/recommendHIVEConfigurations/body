def recommendHIVEConfigurations(self, configurations, clusterData, services, hosts):
    super(HDPWIN22StackAdvisor, self).recommendHiveConfigurations(configurations, clusterData, services, hosts)
    hiveSiteProperties = getSiteProperties(services['configurations'], 'hive-site')
    hiveEnvProperties = getSiteProperties(services['configurations'], 'hive-env')
    putHiveServerProperty = self.putProperty(configurations, 'hiveserver2-site', services)
    putHiveEnvProperty = self.putProperty(configurations, 'hive-env', services)
    putHiveSiteProperty = self.putProperty(configurations, 'hive-site', services)
    putHiveSitePropertyAttribute = self.putPropertyAttribute(configurations, 'hive-site')
    putWebhcatSiteProperty = self.putProperty(configurations, 'webhcat-site', services)
    servicesList = [service['StackServices']['service_name'] for service in services['services']]
    putHiveSiteProperty('datanucleus.autoCreateSchema', 'false')
    putHiveEnvProperty('hive_exec_orc_storage_strategy', 'SPEED')
    putHiveSiteProperty('hive.exec.orc.encoding.strategy', configurations['hive-env']['properties']['hive_exec_orc_storage_strategy'])
    putHiveSiteProperty('hive.exec.orc.compression.strategy', configurations['hive-env']['properties']['hive_exec_orc_storage_strategy'])
    putHiveSiteProperty('hive.exec.orc.default.stripe.size', '67108864')
    putHiveSiteProperty('hive.exec.orc.default.compress', 'ZLIB')
    putHiveSiteProperty('hive.optimize.index.filter', 'true')
    putHiveSiteProperty('hive.optimize.sort.dynamic.partition', 'false')
    putHiveSiteProperty('hive.vectorized.execution.enabled', 'true')
    putHiveSiteProperty('hive.vectorized.execution.reduce.enabled', 'false')
    putHiveEnvProperty('hive_txn_acid', 'off')
    if (str(configurations['hive-env']['properties']['hive_txn_acid']).lower() == 'on'):
        putHiveSiteProperty('hive.txn.manager', 'org.apache.hadoop.hive.ql.lockmgr.DbTxnManager')
        putHiveSiteProperty('hive.support.concurrency', 'true')
        putHiveSiteProperty('hive.compactor.initiator.on', 'true')
        putHiveSiteProperty('hive.compactor.worker.threads', '1')
        putHiveSiteProperty('hive.enforce.bucketing', 'true')
        putHiveSiteProperty('hive.exec.dynamic.partition.mode', 'nonstrict')
    else:
        putHiveSiteProperty('hive.txn.manager', 'org.apache.hadoop.hive.ql.lockmgr.DummyTxnManager')
        putHiveSiteProperty('hive.support.concurrency', 'false')
        putHiveSiteProperty('hive.compactor.initiator.on', 'false')
        putHiveSiteProperty('hive.compactor.worker.threads', '0')
        putHiveSiteProperty('hive.enforce.bucketing', 'false')
        putHiveSiteProperty('hive.exec.dynamic.partition.mode', 'strict')
    putHiveEnvProperty('hive_timeline_logging_enabled', 'true')
    hooks_properties = ['hive.exec.pre.hooks', 'hive.exec.post.hooks', 'hive.exec.failure.hooks']
    include_ats_hook = (str(configurations['hive-env']['properties']['hive_timeline_logging_enabled']).lower() == 'true')
    ats_hook_class = 'org.apache.hadoop.hive.ql.hooks.ATSHook'
    for hooks_property in hooks_properties:
        if (hooks_property in configurations['hive-site']['properties']):
            hooks_value = configurations['hive-site']['properties'][hooks_property]
        else:
            hooks_value = ' '
        if (include_ats_hook and (ats_hook_class not in hooks_value)):
            if (hooks_value == ' '):
                hooks_value = ats_hook_class
            else:
                hooks_value = ((hooks_value + ',') + ats_hook_class)
        if ((not include_ats_hook) and (ats_hook_class in hooks_value)):
            hooks_classes = []
            for hook_class in hooks_value.split(','):
                if ((hook_class != ats_hook_class) and (hook_class != ' ')):
                    hooks_classes.append(hook_class)
            if hooks_classes:
                hooks_value = ','.join(hooks_classes)
            else:
                hooks_value = ' '
        putHiveSiteProperty(hooks_property, hooks_value)
    if ('TEZ' in servicesList):
        putHiveSiteProperty('hive.execution.engine', 'tez')
    else:
        putHiveSiteProperty('hive.execution.engine', 'mr')
    container_size = '512'
    if (not ('yarn-site' in configurations)):
        self.recommendYARNConfigurations(configurations, clusterData, services, hosts)
    yarnMaxAllocationSize = min((30 * int(configurations['yarn-site']['properties']['yarn.scheduler.minimum-allocation-mb'])), int(configurations['yarn-site']['properties']['yarn.scheduler.maximum-allocation-mb']))
    container_size = (clusterData['mapMemory'] if (clusterData['mapMemory'] > 2048) else int(clusterData['reduceMemory']))
    container_size = min((clusterData['containers'] * clusterData['ramPerContainer']), container_size, yarnMaxAllocationSize)
    putHiveSiteProperty('hive.tez.container.size', container_size)
    putHiveSiteProperty('hive.prewarm.enabled', 'false')
    putHiveSiteProperty('hive.prewarm.numcontainers', '3')
    putHiveSiteProperty('hive.tez.auto.reducer.parallelism', 'true')
    putHiveSiteProperty('hive.tez.dynamic.partition.pruning', 'true')
    container_size = configurations['hive-site']['properties']['hive.tez.container.size']
    container_size_bytes = ((int(container_size) * 1024) * 1024)
    putHiveSiteProperty('hive.auto.convert.join.noconditionaltask.size', int((container_size_bytes / 3)))
    putHiveSitePropertyAttribute('hive.auto.convert.join.noconditionaltask.size', 'maximum', container_size_bytes)
    putHiveSiteProperty('hive.exec.reducers.bytes.per.reducer', '67108864')
    if (('hive-site' in services['configurations']) and ('hive.cbo.enable' in services['configurations']['hive-site']['properties'])):
        hive_cbo_enable = services['configurations']['hive-site']['properties']['hive.cbo.enable']
        putHiveSiteProperty('hive.stats.fetch.partition.stats', hive_cbo_enable)
        putHiveSiteProperty('hive.stats.fetch.column.stats', hive_cbo_enable)
    putHiveSiteProperty('hive.compute.query.using.stats', 'true')
    putHiveSiteProperty('hive.server2.tez.initialize.default.sessions', 'false')
    putHiveSiteProperty('hive.server2.tez.sessions.per.default.queue', '1')
    putHiveSiteProperty('hive.server2.enable.doAs', 'true')
    yarn_queues = 'default'
    capacitySchedulerProperties = {}
    if (('capacity-scheduler' in services['configurations']) and ('capacity-scheduler' in services['configurations']['capacity-scheduler']['properties'])):
        properties = str(services['configurations']['capacity-scheduler']['properties']['capacity-scheduler']).split('\n')
        for property in properties:
            (key, sep, value) = property.partition('=')
            capacitySchedulerProperties[key] = value
    if ('yarn.scheduler.capacity.root.queues' in capacitySchedulerProperties):
        yarn_queues = str(capacitySchedulerProperties['yarn.scheduler.capacity.root.queues'])
    putHiveServerPropertyAttribute = self.putPropertyAttribute(configurations, 'hiveserver2-site')
    toProcessQueues = yarn_queues.split(',')
    leafQueueNames = set()
    while (len(toProcessQueues) > 0):
        queue = toProcessQueues.pop()
        queueKey = (('yarn.scheduler.capacity.root.' + queue) + '.queues')
        if (queueKey in capacitySchedulerProperties):
            subQueues = capacitySchedulerProperties[queueKey].split(',')
            for subQueue in subQueues:
                toProcessQueues.append(((queue + '.') + subQueue))
        else:
            queueName = queue.split('.')[(-1)]
            leafQueueNames.add(queueName)
    leafQueues = [{'label': (str(queueName) + ' queue'), 'value': queueName, } for queueName in leafQueueNames]
    leafQueues = sorted(leafQueues, key=(lambda q: q['value']))
    putHiveSitePropertyAttribute('hive.server2.tez.default.queues', 'entries', leafQueues)
    putHiveSiteProperty('hive.server2.tez.default.queues', ','.join([leafQueue['value'] for leafQueue in leafQueues]))
    putHiveEnvProperty('hive_security_authorization', 'None')
    if (str(configurations['hive-env']['properties']['hive_security_authorization']).lower() == 'none'):
        putHiveSiteProperty('hive.security.authorization.enabled', 'false')
        putHiveSiteProperty('hive.security.authorization.manager', 'org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdConfOnlyAuthorizerFactory')
        putHiveServerPropertyAttribute('hive.security.authorization.manager', 'delete', 'true')
        putHiveServerPropertyAttribute('hive.security.authorization.enabled', 'delete', 'true')
        putHiveServerPropertyAttribute('hive.security.authenticator.manager', 'delete', 'true')
    else:
        putHiveSiteProperty('hive.security.authorization.enabled', 'true')
    try:
        auth_manager_value = str(configurations['hive-env']['properties']['hive.security.metastore.authorization.manager'])
    except KeyError:
        auth_manager_value = 'org.apache.hadoop.hive.ql.security.authorization.StorageBasedAuthorizationProvider'
        pass
    auth_manager_values = auth_manager_value.split(',')
    sqlstdauth_class = 'org.apache.hadoop.hive.ql.security.authorization.MetaStoreAuthzAPIAuthorizerEmbedOnly'
    putHiveSiteProperty('hive.server2.enable.doAs', 'true')
    if (str(configurations['hive-env']['properties']['hive_security_authorization']).lower() == 'sqlstdauth'):
        putHiveSiteProperty('hive.server2.enable.doAs', 'false')
        putHiveServerProperty('hive.security.authorization.enabled', 'true')
        putHiveServerProperty('hive.security.authorization.manager', 'org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdHiveAuthorizerFactory')
        putHiveServerProperty('hive.security.authenticator.manager', 'org.apache.hadoop.hive.ql.security.SessionStateUserAuthenticator')
        putHiveSiteProperty('hive.security.authorization.manager', 'org.apache.hadoop.hive.ql.security.authorization.plugin.sqlstd.SQLStdConfOnlyAuthorizerFactory')
        if (sqlstdauth_class not in auth_manager_values):
            auth_manager_values.append(sqlstdauth_class)
    elif (sqlstdauth_class in auth_manager_values):
        auth_manager_values = [x for x in auth_manager_values if (x != sqlstdauth_class)]
        pass
    putHiveSiteProperty('hive.security.metastore.authorization.manager', ','.join(auth_manager_values))
    if (str(configurations['hive-env']['properties']['hive_security_authorization']).lower() == 'ranger'):
        putHiveSiteProperty('hive.server2.enable.doAs', 'false')
        putHiveServerProperty('hive.security.authorization.enabled', 'true')
        putHiveServerProperty('hive.security.authorization.manager', 'org.apache.ranger.authorization.hive.authorizer.RangerHiveAuthorizerFactory')
        putHiveServerProperty('hive.security.authenticator.manager', 'org.apache.hadoop.hive.ql.security.SessionStateUserAuthenticator')
    putHiveSiteProperty('hive.server2.use.SSL', 'false')
    hive_server2_auth = None
    if (('hive-site' in services['configurations']) and ('hive.server2.authentication' in services['configurations']['hive-site']['properties'])):
        hive_server2_auth = str(services['configurations']['hive-site']['properties']['hive.server2.authentication']).lower()
    elif ('hive.server2.authentication' in configurations['hive-site']['properties']):
        hive_server2_auth = str(configurations['hive-site']['properties']['hive.server2.authentication']).lower()
    if (hive_server2_auth == 'ldap'):
        putHiveSiteProperty('hive.server2.authentication.ldap.url', '')
        putHiveSiteProperty('hive.server2.authentication.ldap.baseDN', ' ')
    else:
        putHiveSitePropertyAttribute('hive.server2.authentication.ldap.url', 'delete', 'true')
        putHiveSitePropertyAttribute('hive.server2.authentication.ldap.baseDN', 'delete', 'true')
    if (hive_server2_auth == 'kerberos'):
        putHiveSiteProperty('hive.server2.authentication.kerberos.keytab', '')
        putHiveSiteProperty('hive.server2.authentication.kerberos.principal', '')
    else:
        putHiveSitePropertyAttribute('hive.server2.authentication.kerberos.keytab', 'delete', 'true')
        putHiveSitePropertyAttribute('hive.server2.authentication.kerberos.principal', 'delete', 'true')
    if (hive_server2_auth == 'pam'):
        putHiveSiteProperty('hive.server2.authentication.pam.services', '')
    else:
        putHiveSitePropertyAttribute('hive.server2.authentication.pam.services', 'delete', 'true')
    if (hive_server2_auth == 'custom'):
        putHiveSiteProperty('hive.server2.custom.authentication.class', '')
    else:
        putHiveSitePropertyAttribute('hive.server2.custom.authentication.class', 'delete', 'true')
    python_binary = (os.environ['PYTHON_EXE'] if ('PYTHON_EXE' in os.environ) else sys.executable)
    putWebhcatSiteProperty('templeton.python', python_binary)
    if (hiveEnvProperties and self.checkSiteProperties(hiveEnvProperties, 'hive_database', 'hive_database_type')):
        putHiveEnvProperty('hive_database_type', self.getDBTypeAlias(hiveEnvProperties['hive_database']))
    if (hiveEnvProperties and hiveSiteProperties and self.checkSiteProperties(hiveSiteProperties, 'javax.jdo.option.ConnectionDriverName') and self.checkSiteProperties(hiveEnvProperties, 'hive_database')):
        putHiveSiteProperty('javax.jdo.option.ConnectionDriverName', self.getDBDriver(hiveEnvProperties['hive_database']))
    if (hiveSiteProperties and hiveEnvProperties and self.checkSiteProperties(hiveSiteProperties, 'ambari.hive.db.schema.name', 'javax.jdo.option.ConnectionURL') and self.checkSiteProperties(hiveEnvProperties, 'hive_database')):
        hiveMSHost = self.getHostWithComponent('HIVE', 'HIVE_METASTORE', services, hosts)
        if (hiveMSHost is not None):
            dbConnection = self.getDBConnectionString(hiveEnvProperties['hive_database']).format(hiveMSHost['Hosts']['host_name'], hiveSiteProperties['ambari.hive.db.schema.name'])
            putHiveSiteProperty('javax.jdo.option.ConnectionURL', dbConnection)
