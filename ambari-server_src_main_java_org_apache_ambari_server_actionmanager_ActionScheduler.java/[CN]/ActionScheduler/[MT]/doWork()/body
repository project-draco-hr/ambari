{
  try {
    unitOfWork.begin();
    Set<String> runningRequestIds=new HashSet<String>();
    Set<String> affectedHosts=new HashSet<String>();
    List<Stage> stages=db.getStagesInProgress();
    if (LOG.isDebugEnabled()) {
      LOG.debug("Scheduler wakes up");
      LOG.debug("Processing {} in progress stages ",stages.size());
    }
    if (stages == null || stages.isEmpty()) {
      if (LOG.isDebugEnabled()) {
        LOG.debug("No stage in progress..nothing to do");
      }
      return;
    }
    int i_stage=0;
    for (    Stage s : stages) {
      i_stage++;
      long requestId=s.getRequestId();
      String requestIdStr=String.valueOf(requestId);
      LOG.debug("==> STAGE_i = " + i_stage + "(requestId="+ requestIdStr+ ",StageId="+ s.getStageId()+ ")");
      if (runningRequestIds.contains(requestIdStr)) {
        LOG.info("==> We don't want to process different stages from the same request in parallel");
        continue;
      }
 else {
        runningRequestIds.add(requestIdStr);
        if (!requestsInProgress.contains(requestIdStr)) {
          requestsInProgress.add(requestIdStr);
          db.startRequest(requestId);
        }
      }
      List<String> stageHosts=s.getHosts();
      boolean conflict=false;
      for (      String host : stageHosts) {
        if (affectedHosts.contains(host)) {
          conflict=true;
          break;
        }
      }
      if (conflict) {
        continue;
      }
 else {
        affectedHosts.addAll(stageHosts);
      }
      List<ExecutionCommand> commandsToSchedule=new ArrayList<ExecutionCommand>();
      Map<String,RoleStats> roleStats=processInProgressStage(s,commandsToSchedule);
      boolean failed=false;
      for (      String role : roleStats.keySet()) {
        RoleStats stats=roleStats.get(role);
        if (LOG.isDebugEnabled()) {
          LOG.debug("Stats for role:" + role + ", stats="+ stats);
        }
        if (stats.isRoleFailed()) {
          failed=true;
          break;
        }
      }
      if (!failed) {
        failed=hasPreviousStageFailed(s);
      }
      if (failed) {
        LOG.warn("Operation completely failed, aborting request id:" + s.getRequestId());
        abortOperationsForStage(s);
        return;
      }
      List<ExecutionCommand> commandsToStart=new ArrayList<ExecutionCommand>();
      List<ExecutionCommand> commandsToUpdate=new ArrayList<ExecutionCommand>();
      for (      ExecutionCommand cmd : commandsToSchedule) {
        if (Role.valueOf(cmd.getRole()).equals(Role.AMBARI_SERVER_ACTION)) {
          executeServerAction(s,cmd);
        }
 else {
          processHostRole(s,cmd,commandsToStart,commandsToUpdate);
        }
      }
      LOG.debug("==> Commands to start: {}",commandsToStart.size());
      LOG.debug("==> Commands to update: {}",commandsToUpdate.size());
      ListMultimap<String,ServiceComponentHostEvent> eventMap=formEventMap(s,commandsToStart);
      List<ExecutionCommand> commandsToAbort=new ArrayList<ExecutionCommand>();
      if (!eventMap.isEmpty()) {
        LOG.debug("==> processing {} serviceComponentHostEvents...",eventMap.size());
        Cluster cluster=fsmObject.getCluster(s.getClusterName());
        if (cluster != null) {
          List<ServiceComponentHostEvent> failedEvents=cluster.processServiceComponentHostEvents(eventMap);
          LOG.debug("==> {} events failed.",failedEvents.size());
          for (Iterator<ExecutionCommand> iterator=commandsToUpdate.iterator(); iterator.hasNext(); ) {
            ExecutionCommand cmd=iterator.next();
            for (            ServiceComponentHostEvent event : failedEvents) {
              if (StringUtils.equals(event.getHostName(),cmd.getHostname()) && StringUtils.equals(event.getServiceComponentName(),cmd.getRole())) {
                iterator.remove();
                commandsToAbort.add(cmd);
                break;
              }
            }
          }
        }
 else {
          LOG.warn("There was events to process but cluster {} not found",s.getClusterName());
        }
      }
      LOG.debug("==> Scheduling {} tasks...",commandsToUpdate.size());
      db.bulkHostRoleScheduled(s,commandsToUpdate);
      LOG.debug("==> Aborting {} tasks...",commandsToAbort.size());
      db.bulkAbortHostRole(s,commandsToAbort);
      LOG.debug("==> Adding {} tasks to queue...",commandsToUpdate.size());
      for (      ExecutionCommand cmd : commandsToUpdate) {
        actionQueue.enqueue(cmd.getHostname(),cmd);
      }
      LOG.debug("==> Finished.");
      if (!configuration.getParallelStageExecution()) {
        return;
      }
    }
    requestsInProgress.retainAll(runningRequestIds);
  }
  finally {
    LOG.debug("Scheduler finished work.");
    unitOfWork.end();
  }
}
