def tokenize(self, source, name=None, filename=None, state=None):
    'Calls tokeniter + tokenize and wraps it in a token stream.\n        '
    stream = self.tokeniter(source, name, filename, state)
    return TokenStream(self.wrap(stream, name, filename), name, filename)
