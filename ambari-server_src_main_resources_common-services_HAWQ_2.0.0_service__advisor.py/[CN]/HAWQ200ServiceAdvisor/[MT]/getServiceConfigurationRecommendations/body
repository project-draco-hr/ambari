def getServiceConfigurationRecommendations(self, configurations, clusterData, services, hosts):
    if (('cluster-env' in services['configurations']) and ('security_enabled' in services['configurations']['cluster-env']['properties'])):
        is_secured = services['configurations']['cluster-env']['properties']['security_enabled']
    else:
        is_secured = 'false'
    if ('hdfs-site' in services['configurations']):
        hdfs_site = services['configurations']['hdfs-site']['properties']
        putHdfsSiteProperty = self.putProperty(configurations, 'hdfs-site', services)
        putHdfsSitePropertyAttribute = self.putPropertyAttribute(configurations, 'hdfs-site')
        hdfs_site_desired_values = {'dfs.allow.truncate': 'true', 'dfs.block.access.token.enable': is_secured, 'dfs.block.local-path-access.user': 'gpadmin', 'dfs.client.read.shortcircuit': 'true', 'dfs.client.use.legacy.blockreader.local': 'false', 'dfs.datanode.data.dir.perm': '750', 'dfs.datanode.handler.count': '60', 'dfs.datanode.max.transfer.threads': '40960', 'dfs.namenode.accesstime.precision': '0', 'dfs.namenode.handler.count': '200', 'dfs.support.append': 'true', }
        for (property, desired_value) in hdfs_site_desired_values.iteritems():
            if ((property not in hdfs_site) or (hdfs_site[property] != desired_value)):
                putHdfsSiteProperty(property, desired_value)
    if ('core-site' in services['configurations']):
        core_site = services['configurations']['core-site']['properties']
        putCoreSiteProperty = self.putProperty(configurations, 'core-site', services)
        core_site_desired_values = {'ipc.client.connection.maxidletime': '3600000', 'ipc.server.listen.queue.size': '3300', }
        for (property, desired_value) in core_site_desired_values.iteritems():
            if ((property not in core_site) or (core_site[property] != desired_value)):
                putCoreSiteProperty(property, desired_value)
    if any(((x in services['configurations']) for x in ['hawq-site', 'hdfs-client', 'hawq-sysctl-env'])):
        componentsListList = [service['components'] for service in services['services']]
        componentsList = [item['StackServiceComponents'] for sublist in componentsListList for item in sublist]
        servicesList = [service['StackServices']['service_name'] for service in services['services']]
        hawqMasterHosts = set(self.getHosts(componentsList, 'HAWQMASTER')).union(set(self.getHosts(componentsList, 'HAWQSTANDBY')))
        hawqSegmentHosts = set(self.getHosts(componentsList, 'HAWQSEGMENT'))
        hawqHosts = hawqMasterHosts.union(hawqSegmentHosts)
        numSegments = len(hawqSegmentHosts)
        minHawqHostsMemory = min([host['Hosts']['total_mem'] for host in hosts['items'] if (host['Hosts']['host_name'] in hawqHosts)])
        minHawqHostsCoreCount = min([host['Hosts']['cpu_count'] for host in hosts['items'] if (host['Hosts']['host_name'] in hawqHosts)])
    if ('hawq-site' in services['configurations']):
        hawq_site = services['configurations']['hawq-site']['properties']
        putHawqSiteProperty = self.putProperty(configurations, 'hawq-site', services)
        putHawqSitePropertyAttribute = self.putPropertyAttribute(configurations, 'hawq-site')
        hawq_sysctl_env = services['configurations']['hawq-sysctl-env']['properties']
        putHawqSysctlEnvProperty = self.putProperty(configurations, 'hawq-sysctl-env', services)
        putHawqSysctlEnvPropertyAttribute = self.putPropertyAttribute(configurations, 'hawq-sysctl-env')
        if (self.isHawqMasterComponentOnAmbariServer(services) and ('hawq_master_address_port' in hawq_site)):
            putHawqSiteProperty('hawq_master_address_port', '')
        if (numSegments and ('default_hash_table_bucket_number' in hawq_site) and ('hawq_rm_nvseg_perquery_limit' in hawq_site)):
            factor_min = 1
            factor_max = 6
            limit = int(hawq_site['hawq_rm_nvseg_perquery_limit'])
            factor = (limit / numSegments)
            if (factor < factor_min):
                buckets = limit
            elif (factor > factor_max):
                buckets = (factor_max * numSegments)
            else:
                buckets = (factor * numSegments)
            putHawqSiteProperty('default_hash_table_bucket_number', buckets)
            putHawqSitePropertyAttribute('default_hash_table_bucket_number', 'maximum', ((numSegments * 16) if (10000 > (numSegments * 16)) else 10000))
        if (('YARN' in servicesList) and ('yarn-site' in services['configurations'])):
            yarn_site = services['configurations']['yarn-site']['properties']
            for (hs_prop, ys_prop) in self.getHAWQYARNPropertyMapping().items():
                if ((hs_prop in hawq_site) and (ys_prop in yarn_site)):
                    putHawqSiteProperty(hs_prop, yarn_site[ys_prop])
        putHawqSiteProperty('hawq_rm_nvcore_limit_perseg', minHawqHostsCoreCount)
        if ('vm.overcommit_memory' in hawq_sysctl_env):
            MEM_THRESHOLD = 33554432
            vm_overcommit_ratio = (int(hawq_sysctl_env['vm.overcommit_ratio']) if ('vm.overcommit_ratio' in hawq_sysctl_env) else 50)
            if (('hawq_rm_memory_limit_perseg' in hawq_site) and (hawq_site['hawq_rm_memory_limit_perseg'] == '65535MB')):
                vm_overcommit_mem_value = (2 if (minHawqHostsMemory >= MEM_THRESHOLD) else 1)
            else:
                vm_overcommit_mem_value = int(hawq_sysctl_env['vm.overcommit_memory'])
            putHawqSysctlEnvProperty('vm.overcommit_ratio', vm_overcommit_ratio)
            overcommit_ratio_visibility = ('true' if (vm_overcommit_mem_value == 2) else 'false')
            putHawqSysctlEnvPropertyAttribute('vm.overcommit_ratio', 'visible', overcommit_ratio_visibility)
            putHawqSysctlEnvProperty('vm.overcommit_memory', vm_overcommit_mem_value)
            host_ram_kb = (((minHawqHostsMemory * vm_overcommit_ratio) / 100) if (vm_overcommit_mem_value == 2) else minHawqHostsMemory)
            host_ram_gb = (float(host_ram_kb) / (1024 * 1024))
            recommended_mem_percentage = {(host_ram_gb <= 64): 0.75, (64 < host_ram_gb <= 512): 0.85, (host_ram_gb > 512): 0.95, }[True]
            recommended_mem = math.ceil((host_ram_gb * recommended_mem_percentage))
            unit = 'GB'
            if (recommended_mem >= host_ram_gb):
                recommended_mem = math.ceil(((float(host_ram_kb) / 1024) * recommended_mem_percentage))
                unit = 'MB'
            putHawqSiteProperty('hawq_rm_memory_limit_perseg', '{0}{1}'.format(int(recommended_mem), unit))
        if (('hawq_rm_nvseg_perquery_perseg_limit' in hawq_site) and (int(hawq_site['hawq_rm_nvseg_perquery_perseg_limit']) < 6)):
            putHawqSiteProperty('hawq_rm_nvseg_perquery_perseg_limit', 6)
        if (('hawq_global_rm_type' in hawq_site) and ('hawq_rm_memory_limit_perseg' in hawq_site)):
            hawq_rm_memory_limit_perseg = hawq_site['hawq_rm_memory_limit_perseg'].strip()
            unit = hawq_rm_memory_limit_perseg[(-2):]
            value = hawq_rm_memory_limit_perseg[:(-2)]
            if (((unit == 'GB') and (1 <= int(value) < 2)) or ((unit == 'MB') and (1024 <= int(value) < 2048))):
                factor = 4
                buckets = (min((factor * numSegments), int(hawq_site['default_hash_table_bucket_number'])) if ('default_hash_table_bucket_number' in hawq_site) else (factor * numSegments))
                putHawqSiteProperty('default_hash_table_bucket_number', buckets)
                putHawqSiteProperty('hawq_rm_nvseg_perquery_perseg_limit', factor)
        YARN_MODE = (True if (hawq_site['hawq_global_rm_type'].lower() == 'yarn') else False)
        yarn_mode_properties_visibility = {'hawq_rm_memory_limit_perseg': False, 'hawq_rm_nvcore_limit_perseg': False, 'hawq_rm_yarn_app_name': True, 'hawq_rm_yarn_queue_name': True, 'hawq_rm_yarn_scheduler_address': True, 'hawq_rm_yarn_address': True, }
        for (property, visible_status) in yarn_mode_properties_visibility.iteritems():
            putHawqSitePropertyAttribute(property, 'visible', str((visible_status if YARN_MODE else (not visible_status))).lower())
    if ('hdfs-client' in services['configurations']):
        MIN_NUM_SEGMENT_THRESHOLD = 3
        hdfs_client = services['configurations']['hdfs-client']['properties']
        if ('output.replace-datanode-on-failure' in hdfs_client):
            propertyValue = ('true' if (numSegments > MIN_NUM_SEGMENT_THRESHOLD) else 'false')
            putHdfsClientProperty = self.putProperty(configurations, 'hdfs-client', services)
            putHdfsClientProperty('output.replace-datanode-on-failure', propertyValue)
