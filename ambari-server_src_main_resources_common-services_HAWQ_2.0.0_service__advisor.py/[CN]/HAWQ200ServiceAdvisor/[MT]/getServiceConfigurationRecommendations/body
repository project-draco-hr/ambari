def getServiceConfigurationRecommendations(self, configurations, clusterData, services, hosts):
    putHdfsSiteProperty = self.putProperty(configurations, 'hdfs-site', services)
    putHdfsSiteProperty('dfs.allow.truncate', 'true')
    if any(((x in services['configurations']) for x in ['hawq-site', 'hdfs-client', 'hawq-sysctl-env'])):
        componentsListList = [service['components'] for service in services['services']]
        componentsList = [item['StackServiceComponents'] for sublist in componentsListList for item in sublist]
        servicesList = [service['StackServices']['service_name'] for service in services['services']]
        hawqMasterHosts = set(self.getHosts(componentsList, 'HAWQMASTER')).union(set(self.getHosts(componentsList, 'HAWQSTANDBY')))
        hawqSegmentHosts = set(self.getHosts(componentsList, 'HAWQSEGMENT'))
        hawqHosts = hawqMasterHosts.union(hawqSegmentHosts)
        numSegments = len(hawqSegmentHosts)
        minHawqHostsMemory = min([host['Hosts']['total_mem'] for host in hosts['items'] if (host['Hosts']['host_name'] in hawqHosts)])
        minHawqHostsCoreCount = min([host['Hosts']['cpu_count'] for host in hosts['items'] if (host['Hosts']['host_name'] in hawqHosts)])
    hawq_site = services['configurations']['hawq-site']['properties']
    putHawqSiteProperty = self.putProperty(configurations, 'hawq-site', services)
    putHawqSitePropertyAttribute = self.putPropertyAttribute(configurations, 'hawq-site')
    hawq_sysctl_env = services['configurations']['hawq-sysctl-env']['properties']
    putHawqSysctlEnvProperty = self.putProperty(configurations, 'hawq-sysctl-env', services)
    if (self.isHawqMasterComponentOnAmbariServer(services) and ('hawq_master_address_port' in hawq_site)):
        putHawqSiteProperty('hawq_master_address_port', '')
    if (numSegments and ('default_hash_table_bucket_number' in hawq_site) and ('hawq_rm_nvseg_perquery_limit' in hawq_site)):
        factor_min = 1
        factor_max = 6
        limit = int(hawq_site['hawq_rm_nvseg_perquery_limit'])
        factor = (limit / numSegments)
        if (factor < factor_min):
            buckets = limit
        elif (factor > factor_max):
            buckets = (factor_max * numSegments)
        else:
            buckets = (factor * numSegments)
        putHawqSiteProperty('default_hash_table_bucket_number', buckets)
    if (('YARN' in servicesList) and ('yarn-site' in services['configurations'])):
        yarn_site = services['configurations']['yarn-site']['properties']
        for (hs_prop, ys_prop) in self.getHAWQYARNPropertyMapping().items():
            if ((hs_prop in hawq_site) and (ys_prop in yarn_site)):
                putHawqSiteProperty(hs_prop, yarn_site[ys_prop])
    putHawqSiteProperty('hawq_rm_nvcore_limit_perseg', minHawqHostsCoreCount)
    if ('vm.overcommit_memory' in hawq_sysctl_env):
        MEM_THRESHOLD = 33554432
        vm_overcommit_ratio = (int(hawq_sysctl_env['vm.overcommit_ratio']) if ('vm.overcommit_ratio' in hawq_sysctl_env) else 50)
        if (('hawq_rm_memory_limit_perseg' in hawq_site) and (hawq_site['hawq_rm_memory_limit_perseg'] == '65535MB')):
            vm_overcommit_mem_value = (2 if (minHawqHostsMemory >= MEM_THRESHOLD) else 1)
        else:
            vm_overcommit_mem_value = int(hawq_sysctl_env['vm.overcommit_memory'])
        putHawqSysctlEnvProperty('vm.overcommit_ratio', vm_overcommit_ratio)
        putHawqSysctlEnvProperty('vm.overcommit_memory', vm_overcommit_mem_value)
        host_ram_kb = (((minHawqHostsMemory * vm_overcommit_ratio) / 100) if (vm_overcommit_mem_value == 2) else minHawqHostsMemory)
        host_ram_gb = (float(host_ram_kb) / (1024 * 1024))
        recommended_mem_percentage = {(host_ram_gb <= 64): 0.75, (64 < host_ram_gb <= 512): 0.85, (host_ram_gb > 512): 0.95, }[True]
        recommended_mem = math.ceil((host_ram_gb * recommended_mem_percentage))
        unit = 'GB'
        if (recommended_mem >= host_ram_gb):
            recommended_mem = math.ceil(((float(host_ram_kb) / 1024) * recommended_mem_percentage))
            unit = 'MB'
        putHawqSiteProperty('hawq_rm_memory_limit_perseg', '{0}{1}'.format(int(recommended_mem), unit))
    YARN_MODE = (True if (hawq_site['hawq_global_rm_type'].lower() == 'yarn') else False)
    yarn_mode_properties_visibility = {'hawq_rm_memory_limit_perseg': False, 'hawq_rm_nvcore_limit_perseg': False, 'hawq_rm_yarn_app_name': True, 'hawq_rm_yarn_queue_name': True, 'hawq_rm_yarn_scheduler_address': True, 'hawq_rm_yarn_address': True, }
    for (property, visible_status) in yarn_mode_properties_visibility.iteritems():
        putHawqSitePropertyAttribute(property, 'visible', str((visible_status if YARN_MODE else (not visible_status))).lower())
    if ('hdfs-client' in services['configurations']):
        MIN_NUM_SEGMENT_THRESHOLD = 3
        hdfs_client = services['configurations']['hdfs-client']['properties']
        if ('output.replace-datanode-on-failure' in hdfs_client):
            propertyValue = ('true' if (numSegments > MIN_NUM_SEGMENT_THRESHOLD) else 'false')
            putHdfsClientProperty = self.putProperty(configurations, 'hdfs-client', services)
            putHdfsClientProperty('output.replace-datanode-on-failure', propertyValue)
