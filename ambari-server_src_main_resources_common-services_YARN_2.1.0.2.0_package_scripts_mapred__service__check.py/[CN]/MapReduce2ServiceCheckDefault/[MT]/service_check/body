def service_check(self, env):
    import params
    env.set_params(params)
    jar_path = format('{hadoop_mapred2_jar_location}/{hadoopMapredExamplesJarName}')
    input_file = format('/user/{smokeuser}/mapredsmokeinput')
    output_file = format('/user/{smokeuser}/mapredsmokeoutput')
    test_cmd = format('fs -test -e {output_file}')
    run_wordcount_job = format('jar {jar_path} wordcount {input_file} {output_file}')
    params.HdfsResource(output_file, action='delete_on_execute', type='directory', dfs_type=params.dfs_type)
    params.HdfsResource(input_file, action='create_on_execute', type='file', source='/etc/passwd', dfs_type=params.dfs_type)
    params.HdfsResource(None, action='execute')
    if params.security_enabled:
        kinit_cmd = format('{kinit_path_local} -kt {smoke_user_keytab} {smokeuser_principal};')
        Execute(kinit_cmd, user=params.smokeuser)
    ExecuteHadoop(run_wordcount_job, tries=1, try_sleep=5, user=params.smokeuser, bin_dir=params.execute_path, conf_dir=params.hadoop_conf_dir, logoutput=True)
    if params.security_enabled:
        kinit_cmd = format('{kinit_path_local} -kt {smoke_user_keytab} {smokeuser_principal};')
        Execute(kinit_cmd, user=params.smokeuser)
    ExecuteHadoop(test_cmd, user=params.smokeuser, bin_dir=params.execute_path, conf_dir=params.hadoop_conf_dir)
