{
  try {
    UserGroupInformation ugi=UserGroupInformation.createRemoteUser("hdfs");
    ugi.doAs(new PrivilegedExceptionAction<Void>(){
      public Void run() throws Exception {
        Configuration conf=new Configuration();
        conf.set("fs.hdfs.impl",org.apache.hadoop.hdfs.DistributedFileSystem.class.getName());
        conf.set("fs.file.impl",org.apache.hadoop.fs.LocalFileSystem.class.getName());
        conf.set("fs.defaultFS",namenodeuri);
        conf.set("hadoop.job.ugi","hdfs");
        FileSystem fileSystem=FileSystem.get(conf);
        String filename=source.substring(source.lastIndexOf('/') + 1,source.length());
        String dest1;
        if (dest.charAt(dest.length() - 1) != '/') {
          dest1=dest + "/" + filename;
        }
 else {
          dest1=dest + filename;
        }
        Path path=new Path(dest1);
        if (fileSystem.exists(path)) {
        }
        FSDataOutputStream out=fileSystem.create(path);
        InputStream in=new BufferedInputStream(new FileInputStream(new File(source)));
        byte[] b=new byte[1024];
        int numBytes=0;
        while ((numBytes=in.read(b)) > 0) {
          out.write(b,0,numBytes);
        }
        in.close();
        out.close();
        fileSystem.setOwner(path,username,"hadoop");
        fileSystem.close();
        return null;
      }
    }
);
  }
 catch (  Exception e) {
    logger.error("Webhdfs Exception: ",e);
  }
}
