{
  EasyMockSupport mockSupport=new EasyMockSupport();
  CredentialStoreService credentialStoreServiceMock=mockSupport.createMock(CredentialStoreService.class);
  Cluster clusterMock=mockSupport.createMock(Cluster.class);
  LoggingRequestHelperImpl.NetworkConnection networkConnectionMock=mockSupport.createMock(LoggingRequestHelperImpl.NetworkConnection.class);
  Config adminPropertiesConfigMock=mockSupport.createMock(Config.class);
  Map<String,String> testConfigProperties=new HashMap<String,String>();
  testConfigProperties.put("logsearch_admin_username",EXPECTED_USER_NAME);
  testConfigProperties.put("logsearch_admin_password",EXPECTED_ADMIN_PASSWORD);
  testConfigProperties=Collections.unmodifiableMap(testConfigProperties);
  Capture<HttpURLConnection> captureURLConnection=new Capture<HttpURLConnection>();
  Capture<HttpURLConnection> captureURLConnectionForAuthentication=new Capture<HttpURLConnection>();
  expect(clusterMock.getDesiredConfigByType("logsearch-admin-json")).andReturn(adminPropertiesConfigMock).atLeastOnce();
  expect(adminPropertiesConfigMock.getProperties()).andReturn(testConfigProperties).atLeastOnce();
  expect(networkConnectionMock.readQueryResponseFromServer(capture(captureURLConnection))).andReturn(new StringBuffer(TEST_JSON_INPUT_TWO_LIST_ENTRIES)).atLeastOnce();
  networkConnectionMock.setupBasicAuthentication(capture(captureURLConnectionForAuthentication),eq(EXPECTED_ENCODED_CREDENTIALS));
  mockSupport.replayAll();
  LoggingRequestHelper helper=new LoggingRequestHelperImpl(EXPECTED_HOST_NAME,EXPECTED_PORT_NUMBER,credentialStoreServiceMock,clusterMock,networkConnectionMock);
  LogQueryResponse result=helper.sendQueryRequest(Collections.<String,String>emptyMap());
  HttpURLConnection httpURLConnection=captureURLConnection.getValue();
  assertEquals("URLConnection did not have the correct hostname information",EXPECTED_HOST_NAME,httpURLConnection.getURL().getHost());
  assertEquals("URLConnection did not have the correct port information",EXPECTED_PORT_NUMBER,httpURLConnection.getURL().getPort() + "");
  assertEquals("URLConnection did not have the expected http protocol scheme","http",httpURLConnection.getURL().getProtocol());
  assertEquals("URLConnection did not have the expected method set","GET",httpURLConnection.getRequestMethod());
  assertSame("HttpUrlConnection instances passed into NetworkConnection mock should have been the same instance",httpURLConnection,captureURLConnectionForAuthentication.getValue());
  assertNotNull("Response object should not be null",result);
  assertEquals("startIndex not parsed properly","0",result.getStartIndex());
  assertEquals("pageSize not parsed properly","5",result.getPageSize());
  assertEquals("totalCount not parsed properly","10452",result.getTotalCount());
  assertEquals("resultSize not parsed properly","5",result.getResultSize());
  assertEquals("queryTimeMS not parsed properly","1458148754113",result.getQueryTimeMS());
  assertEquals("incorrect number of LogLineResult items parsed",2,result.getListOfResults().size());
  List<LogLineResult> listOfLineResults=result.getListOfResults();
{
    LogLineResult resultOne=listOfLineResults.get(0);
    assertEquals("Cluster name not parsed properly","clusterone",resultOne.getClusterName());
    assertEquals("Method Name not parsed properly","chooseUnderReplicatedBlocks",resultOne.getLogMethod());
    assertEquals("Log Level not parsed properly","INFO",resultOne.getLogLevel());
    assertEquals("event_count not parsed properly","1",resultOne.getEventCount());
    assertEquals("ip address not parsed properly","192.168.1.1",resultOne.getIpAddress());
    assertEquals("component type not parsed properly","hdfs_namenode",resultOne.getComponentType());
    assertEquals("sequence number not parsed properly","10584",resultOne.getSequenceNumber());
    assertEquals("log file path not parsed properly","/var/log/hadoop/hdfs/hadoop-hdfs-namenode-c6401.ambari.apache.org.log",resultOne.getLogFilePath());
    assertEquals("log src file name not parsed properly","UnderReplicatedBlocks.java",resultOne.getSourceFile());
    assertEquals("log src line number not parsed properly","394",resultOne.getSourceFileLineNumber());
    assertEquals("host name not parsed properly","c6401.ambari.apache.org",resultOne.getHostName());
    assertEquals("log message not parsed properly","chooseUnderReplicatedBlocks selected 2 blocks at priority level 0;  Total=2 Reset bookmarks? false",resultOne.getLogMessage());
    assertEquals("logger name not parsed properly","BlockStateChange",resultOne.getLoggerName());
    assertEquals("id not parsed properly","9c5562fb-123f-47c8-aaf5-b5e407326c08",resultOne.getId());
    assertEquals("message MD5 not parsed properly","-3892769501348410581",resultOne.getMessageMD5());
    assertEquals("log time not parsed properly","1458148749036",resultOne.getLogTime());
    assertEquals("event MD5 not parsed properly","1458148749036-2417481968206345035",resultOne.getEventMD5());
    assertEquals("logfile line number not parsed properly","2084",resultOne.getLogFileLineNumber());
    assertEquals("ttl not parsed properly","+7DAYS",resultOne.getTtl());
    assertEquals("expire at not parsed properly","1458753550322",resultOne.getExpirationTime());
    assertEquals("version not parsed properly","1528979784023932928",resultOne.getVersion());
  }
{
    LogLineResult resultTwo=listOfLineResults.get(1);
    assertEquals("Cluster name not parsed properly","clusterone",resultTwo.getClusterName());
    assertEquals("Method Name not parsed properly","putMetrics",resultTwo.getLogMethod());
    assertEquals("Log Level not parsed properly","WARN",resultTwo.getLogLevel());
    assertEquals("event_count not parsed properly","1",resultTwo.getEventCount());
    assertEquals("ip address not parsed properly","192.168.1.1",resultTwo.getIpAddress());
    assertEquals("component type not parsed properly","yarn_resourcemanager",resultTwo.getComponentType());
    assertEquals("sequence number not parsed properly","10583",resultTwo.getSequenceNumber());
    assertEquals("log file path not parsed properly","/var/log/hadoop-yarn/yarn/yarn-yarn-resourcemanager-c6401.ambari.apache.org.log",resultTwo.getLogFilePath());
    assertEquals("log src file name not parsed properly","HadoopTimelineMetricsSink.java",resultTwo.getSourceFile());
    assertEquals("log src line number not parsed properly","262",resultTwo.getSourceFileLineNumber());
    assertEquals("host name not parsed properly","c6401.ambari.apache.org",resultTwo.getHostName());
    assertEquals("log message not parsed properly","Unable to send metrics to collector by address:http://c6401.ambari.apache.org:6188/ws/v1/timeline/metrics",resultTwo.getLogMessage());
    assertEquals("logger name not parsed properly","timeline.HadoopTimelineMetricsSink",resultTwo.getLoggerName());
    assertEquals("id not parsed properly","8361c5a9-5b1c-4f44-bc8f-4c6f07d94228",resultTwo.getId());
    assertEquals("message MD5 not parsed properly","5942185045779825717",resultTwo.getMessageMD5());
    assertEquals("log time not parsed properly","1458148746937",resultTwo.getLogTime());
    assertEquals("event MD5 not parsed properly","14581487469371427138486123628676",resultTwo.getEventMD5());
    assertEquals("logfile line number not parsed properly","549",resultTwo.getLogFileLineNumber());
    assertEquals("ttl not parsed properly","+7DAYS",resultTwo.getTtl());
    assertEquals("expire at not parsed properly","1458753550322",resultTwo.getExpirationTime());
    assertEquals("version not parsed properly","1528979784022884357",resultTwo.getVersion());
  }
  mockSupport.verifyAll();
}
