def setup_atlas_jar_symlinks(hook_name, jar_source_dir):
    '\n  In HDP 2.3, 2.4, and 2.5.0.0, Sqoop and Storm still relied on the following method to setup Atlas hooks\n  because the RPM for Sqoop and Storm did not bring in any dependencies.\n\n  /usr/hdp/current/storm-*/libext/ should contain symlinks for every jar in /usr/hdp/current/atlas-server/hooks/storm/somejavafile.jar\n  /usr/hdp/current/sqoop-*/lib/    should contain symlinks for every jar in /usr/hdp/current/atlas-server/hooks/sqoop/somejavafile.jar\n\n  In HDP 2.5.x.y, we plan to have the Sqoop and Storm rpms have additional dependencies on some sqoop-atlas-hook and storm-atlas-hook\n  rpms, respectively, that will bring in the necessary jars and create the symlinks.\n\n  If atlas is present on this host, then link the jars from\n  {stack_root}/current/{hook_name}/lib/name_version.jar -> {jar_source_dir}/name_version.jar\n  @param hook_name: one of sqoop, storm\n  @param jar_source_dir: directory of where the symlinks need to be created from.\n  '
    import params
    if has_atlas_in_cluster():
        atlas_home_dir = (os.environ['METADATA_HOME_DIR'] if ('METADATA_HOME_DIR' in os.environ) else format('{stack_root}/current/atlas-server'))
        atlas_hook_dir = os.path.join(atlas_home_dir, 'hook', hook_name)
        if os.path.exists(atlas_hook_dir):
            Logger.info(('Atlas Server is present on this host, will symlink jars inside of %s to %s if not already done.' % (jar_source_dir, atlas_hook_dir)))
            src_files = os.listdir(atlas_hook_dir)
            for file_name in src_files:
                atlas_hook_file_name = os.path.join(atlas_hook_dir, file_name)
                source_lib_file_name = os.path.join(jar_source_dir, file_name)
                if os.path.isfile(atlas_hook_file_name):
                    Link(source_lib_file_name, to=atlas_hook_file_name)
