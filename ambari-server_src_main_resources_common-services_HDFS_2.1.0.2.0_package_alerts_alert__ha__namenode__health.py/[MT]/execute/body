def execute(configurations={}, parameters={}, host_name=None):
    '\n  Returns a tuple containing the result code and a pre-formatted result label\n\n  Keyword arguments:\n  configurations (dictionary): a mapping of configuration key to value\n  parameters (dictionary): a mapping of script parameter key to value\n  host_name (string): the name of this host where the alert is running\n  '
    if (configurations is None):
        return (RESULT_STATE_UNKNOWN, ['There were no configurations supplied to the script.'])
    if (not (NAMESERVICE_KEY in configurations)):
        return (RESULT_STATE_SKIPPED, ['NameNode HA is not enabled'])
    if (not (HDFS_SITE_KEY in configurations)):
        return (RESULT_STATE_UNKNOWN, ['{0} is a required parameter for the script'.format(HDFS_SITE_KEY)])
    if (SMOKEUSER_KEY in configurations):
        smokeuser = configurations[SMOKEUSER_KEY]
    executable_paths = None
    if (EXECUTABLE_SEARCH_PATHS in configurations):
        executable_paths = configurations[EXECUTABLE_SEARCH_PATHS]
    connection_timeout = CONNECTION_TIMEOUT_DEFAULT
    if (CONNECTION_TIMEOUT_KEY in parameters):
        connection_timeout = float(parameters[CONNECTION_TIMEOUT_KEY])
    security_enabled = False
    if (SECURITY_ENABLED_KEY in configurations):
        security_enabled = (str(configurations[SECURITY_ENABLED_KEY]).upper() == 'TRUE')
    kerberos_keytab = None
    if (KERBEROS_KEYTAB in configurations):
        kerberos_keytab = configurations[KERBEROS_KEYTAB]
    kerberos_principal = None
    if (KERBEROS_PRINCIPAL in configurations):
        kerberos_principal = configurations[KERBEROS_PRINCIPAL]
        kerberos_principal = kerberos_principal.replace('_HOST', host_name)
    is_ssl_enabled = False
    if (DFS_POLICY_KEY in configurations):
        dfs_policy = configurations[DFS_POLICY_KEY]
        if (dfs_policy == 'HTTPS_ONLY'):
            is_ssl_enabled = True
    name_service = configurations[NAMESERVICE_KEY]
    hdfs_site = configurations[HDFS_SITE_KEY]
    nn_unique_ids_key = ('dfs.ha.namenodes.' + name_service)
    if (not (nn_unique_ids_key in hdfs_site)):
        return (RESULT_STATE_UNKNOWN, ['Unable to find unique namenode alias key {0}'.format(nn_unique_ids_key)])
    namenode_http_fragment = NAMENODE_HTTP_FRAGMENT
    jmx_uri_fragment = 'http://{0}/jmx?qry=Hadoop:service=NameNode,name=*'
    if is_ssl_enabled:
        namenode_http_fragment = NAMENODE_HTTPS_FRAGMENT
        jmx_uri_fragment = 'https://{0}/jmx?qry=Hadoop:service=NameNode,name=*'
    active_namenodes = []
    standby_namenodes = []
    unknown_namenodes = []
    nn_unique_ids = hdfs_site[nn_unique_ids_key].split(',')
    for nn_unique_id in nn_unique_ids:
        key = namenode_http_fragment.format(name_service, nn_unique_id)
        rpc_key = NAMENODE_RPC_FRAGMENT.format(name_service, nn_unique_id)
        if (key in hdfs_site):
            value = str(hdfs_site[key])
            if ((INADDR_ANY in value) and (rpc_key in hdfs_site)):
                rpc_value = str(hdfs_site[rpc_key])
                if (INADDR_ANY not in rpc_value):
                    rpc_host = rpc_value.split(':')[0]
                    value = value.replace(INADDR_ANY, rpc_host)
            try:
                jmx_uri = jmx_uri_fragment.format(value)
                if ((kerberos_principal is not None) and (kerberos_keytab is not None) and security_enabled):
                    env = Environment.get_instance()
                    curl_connection_timeout = int(connection_timeout)
                    (state_response, error_msg, time_millis) = curl_krb_request(env.tmp_dir, kerberos_keytab, kerberos_principal, jmx_uri, 'ha_nn_health', executable_paths, False, 'NameNode High Availability Health', smokeuser, connection_timeout=curl_connection_timeout)
                    state = _get_ha_state_from_json(state_response)
                else:
                    state_response = get_jmx(jmx_uri, connection_timeout)
                    state = _get_ha_state_from_json(state_response)
                if (state == HDFS_NN_STATE_ACTIVE):
                    active_namenodes.append(value)
                elif (state == HDFS_NN_STATE_STANDBY):
                    standby_namenodes.append(value)
                else:
                    unknown_namenodes.append(value)
            except:
                logger.exception(LOGGER_EXCEPTION_MESSAGE.format(host_name))
                unknown_namenodes.append(value)
    is_active_namenode = False
    for active_namenode in active_namenodes:
        if active_namenode.startswith(host_name):
            is_active_namenode = True
    is_topology_healthy = ((len(active_namenodes) == 1) and (len(standby_namenodes) == 1))
    result_label = 'Active{0}, Standby{1}, Unknown{2}'.format(str(active_namenodes), str(standby_namenodes), str(unknown_namenodes))
    if is_topology_healthy:
        if (is_active_namenode is True):
            return (RESULT_STATE_OK, [result_label])
        else:
            return (RESULT_STATE_SKIPPED, ['Another host will report this alert'])
    else:
        first_listed_host_key = 'dfs.namenode.rpc-address.{0}.{1}'.format(name_service, nn_unique_ids[0])
        first_listed_host = ''
        if (first_listed_host_key in hdfs_site):
            first_listed_host = hdfs_site[first_listed_host_key]
        is_first_listed_host = False
        if first_listed_host.startswith(host_name):
            is_first_listed_host = True
        if is_first_listed_host:
            return (RESULT_STATE_CRITICAL, [result_label])
        else:
            return (RESULT_STATE_SKIPPED, ['Another host will report this alert'])
