def get_content(self):
    if (self.download_path and (not os.path.exists(self.download_path))):
        raise Fail("Directory {0} doesn't exist, please provide valid download path".format(self.download_path))
    if urlparse.urlparse(self.url).path:
        filename = os.path.basename(urlparse.urlparse(self.url).path)
    else:
        filename = 'index.html.{0}'.format(time.time())
    filepath = os.path.join(self.download_path, filename)
    if ((not self.cache) or (not os.path.exists(filepath))):
        Logger.info('Downloading the file from {0}'.format(self.url))
        if self.ignore_proxy:
            opener = urllib2.build_opener(urllib2.ProxyHandler({}))
        else:
            opener = urllib2.build_opener()
        req = urllib2.Request(self.url)
        try:
            web_file = opener.open(req)
        except urllib2.HTTPError as ex:
            raise Fail('Failed to download file from {0} due to HTTP error: {1}'.format(self.url, str(ex)))
        content = web_file.read()
        if self.cache:
            with open(filepath, 'w') as fp:
                fp.write(content)
    else:
        Logger.info('Not downloading the file from {0}, because {1} already exists'.format(self.url, filepath))
        with open(filepath) as fp:
            content = fp.read()
    return content
