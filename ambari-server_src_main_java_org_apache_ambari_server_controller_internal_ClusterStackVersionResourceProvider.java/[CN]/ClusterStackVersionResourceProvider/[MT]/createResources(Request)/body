{
  Iterator<Map<String,Object>> iterator=request.getProperties().iterator();
  String clName;
  final String desiredRepoVersion;
  String stackName;
  String stackVersion;
  if (request.getProperties().size() != 1) {
    throw new UnsupportedOperationException("Multiple requests cannot be executed at the same time.");
  }
  Map<String,Object> propertyMap=iterator.next();
  Set<String> requiredProperties=new HashSet<String>(){
{
      add(CLUSTER_STACK_VERSION_CLUSTER_NAME_PROPERTY_ID);
      add(CLUSTER_STACK_VERSION_REPOSITORY_VERSION_PROPERTY_ID);
      add(CLUSTER_STACK_VERSION_STACK_PROPERTY_ID);
      add(CLUSTER_STACK_VERSION_VERSION_PROPERTY_ID);
    }
  }
;
  for (  String requiredProperty : requiredProperties) {
    if (!propertyMap.containsKey(requiredProperty)) {
      throw new IllegalArgumentException(String.format("The required property %s is not defined",requiredProperty));
    }
  }
  clName=(String)propertyMap.get(CLUSTER_STACK_VERSION_CLUSTER_NAME_PROPERTY_ID);
  desiredRepoVersion=(String)propertyMap.get(CLUSTER_STACK_VERSION_REPOSITORY_VERSION_PROPERTY_ID);
  Cluster cluster;
  Map<String,Host> hostsForCluster;
  AmbariManagementController managementController=getManagementController();
  AmbariMetaInfo ami=managementController.getAmbariMetaInfo();
  try {
    cluster=managementController.getClusters().getCluster(clName);
    hostsForCluster=managementController.getClusters().getHostsForCluster(clName);
  }
 catch (  AmbariException e) {
    throw new NoSuchParentResourceException(e.getMessage(),e);
  }
  final StackId stackId;
  if (propertyMap.containsKey(CLUSTER_STACK_VERSION_STACK_PROPERTY_ID) && propertyMap.containsKey(CLUSTER_STACK_VERSION_VERSION_PROPERTY_ID)) {
    stackName=(String)propertyMap.get(CLUSTER_STACK_VERSION_STACK_PROPERTY_ID);
    stackVersion=(String)propertyMap.get(CLUSTER_STACK_VERSION_VERSION_PROPERTY_ID);
    stackId=new StackId(stackName,stackVersion);
    if (!ami.isSupportedStack(stackName,stackVersion)) {
      throw new NoSuchParentResourceException(String.format("Stack %s is not supported",stackId));
    }
  }
 else {
    StackId currentStackVersion=cluster.getCurrentStackVersion();
    stackId=currentStackVersion;
  }
  RepositoryVersionEntity repoVersionEnt=repositoryVersionDAO.findByStackAndVersion(stackId,desiredRepoVersion);
  if (repoVersionEnt == null) {
    throw new IllegalArgumentException(String.format("Repo version %s is not available for stack %s",desiredRepoVersion,stackId));
  }
  List<OperatingSystemEntity> operatingSystems=repoVersionEnt.getOperatingSystems();
  Map<String,List<RepositoryEntity>> perOsRepos=new HashMap<String,List<RepositoryEntity>>();
  for (  OperatingSystemEntity operatingSystem : operatingSystems) {
    perOsRepos.put(operatingSystem.getOsType(),operatingSystem.getRepositories());
  }
  RequestStageContainer req=createRequest();
  Iterator<Host> hostsForClusterIter=hostsForCluster.values().iterator();
  Map<String,String> hostLevelParams=new HashMap<String,String>();
  hostLevelParams.put(JDK_LOCATION,getManagementController().getJdkResourceUrl());
  String hostParamsJson=StageUtils.getGson().toJson(hostLevelParams);
  int maxTasks=configuration.getAgentPackageParallelCommandsLimit();
  int hostCount=hostsForCluster.size();
  int batchCount=(int)(Math.ceil((double)hostCount / maxTasks));
  ArrayList<Host> directTransitions=new ArrayList<Host>();
  long stageId=req.getLastStageId() + 1;
  if (0L == stageId) {
    stageId=1L;
  }
  ArrayList<Stage> stages=new ArrayList<Stage>(batchCount);
  for (int batchId=1; batchId <= batchCount; batchId++) {
    String stageName;
    if (batchCount > 1) {
      stageName=INSTALL_PACKAGES_FULL_NAME;
    }
 else {
      stageName=String.format(INSTALL_PACKAGES_FULL_NAME + ". Batch %d of %d",batchId,batchCount);
    }
    Stage stage=stageFactory.createNew(req.getId(),"/tmp/ambari",cluster.getClusterName(),cluster.getClusterId(),stageName,"{}","{}",hostParamsJson);
    stage.setStageId(stageId);
    stages.add(stage);
    stageId++;
    for (int i=0; i < maxTasks && hostsForClusterIter.hasNext(); i++) {
      Host host=hostsForClusterIter.next();
      if (hostHasVersionableComponents(cluster,ami,stackId,host)) {
        addHostVersionInstallCommandsToStage(desiredRepoVersion,cluster,managementController,ami,stackId,perOsRepos,stage,host);
      }
 else {
        directTransitions.add(host);
      }
    }
  }
  req.addStages(stages);
  try {
    ClusterVersionEntity existingCSVer=clusterVersionDAO.findByClusterAndStackAndVersion(clName,stackId,desiredRepoVersion);
    if (existingCSVer == null) {
      try {
        cluster.createClusterVersion(stackId,desiredRepoVersion,managementController.getAuthName(),RepositoryVersionState.INSTALLING);
        existingCSVer=clusterVersionDAO.findByClusterAndStackAndVersion(clName,stackId,desiredRepoVersion);
      }
 catch (      AmbariException e) {
        throw new SystemException(String.format("Can not create cluster stack version %s for cluster %s",desiredRepoVersion,clName),e);
      }
    }
 else {
      cluster.transitionClusterVersion(stackId,desiredRepoVersion,RepositoryVersionState.INSTALLING);
    }
    cluster.inferHostVersions(existingCSVer);
    for (    Host host : directTransitions) {
      transitionHostVersionToInstalled(host,cluster,existingCSVer.getRepositoryVersion().getVersion());
    }
    req.persist();
  }
 catch (  AmbariException e) {
    throw new SystemException("Can not persist request",e);
  }
  return getRequestStatus(req.getRequestStatusResponse());
}
