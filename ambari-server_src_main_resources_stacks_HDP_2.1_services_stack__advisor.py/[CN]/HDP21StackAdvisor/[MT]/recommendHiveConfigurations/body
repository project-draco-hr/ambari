def recommendHiveConfigurations(self, configurations, clusterData, services, hosts):
    hiveSiteProperties = getSiteProperties(services['configurations'], 'hive-site')
    hiveEnvProperties = getSiteProperties(services['configurations'], 'hive-env')
    containerSize = (clusterData['mapMemory'] if (clusterData['mapMemory'] > 2048) else int(clusterData['reduceMemory']))
    containerSize = min((clusterData['containers'] * clusterData['ramPerContainer']), containerSize)
    container_size_bytes = ((int(containerSize) * 1024) * 1024)
    putHiveEnvProperty = self.putProperty(configurations, 'hive-env', services)
    putHiveProperty = self.putProperty(configurations, 'hive-site', services)
    putHiveProperty('hive.auto.convert.join.noconditionaltask.size', int(round((container_size_bytes / 3))))
    putHiveProperty('hive.tez.java.opts', (('-server -Xmx' + str(int(round(((0.8 * containerSize) + 0.5))))) + 'm -Djava.net.preferIPv4Stack=true -XX:NewRatio=8 -XX:+UseNUMA -XX:+UseParallelGC -XX:+PrintGCDetails -verbose:gc -XX:+PrintGCTimeStamps'))
    putHiveProperty('hive.tez.container.size', containerSize)
    if (hiveEnvProperties and self.checkSiteProperties(hiveEnvProperties, 'hive_database', 'hive_database_type')):
        putHiveEnvProperty('hive_database_type', self.getDBTypeAlias(hiveEnvProperties['hive_database']))
    if (hiveEnvProperties and hiveSiteProperties and self.checkSiteProperties(hiveSiteProperties, 'javax.jdo.option.ConnectionDriverName') and self.checkSiteProperties(hiveEnvProperties, 'hive_database')):
        putHiveProperty('javax.jdo.option.ConnectionDriverName', self.getDBDriver(hiveEnvProperties['hive_database']))
    if (hiveSiteProperties and hiveEnvProperties and self.checkSiteProperties(hiveSiteProperties, 'ambari.hive.db.schema.name', 'javax.jdo.option.ConnectionURL') and self.checkSiteProperties(hiveEnvProperties, 'hive_database')):
        hiveServerHost = self.getHostWithComponent('HIVE', 'HIVE_SERVER', services, hosts)
        hiveDBConnectionURL = hiveSiteProperties['javax.jdo.option.ConnectionURL']
        protocol = self.getProtocol(hiveEnvProperties['hive_database'])
        oldSchemaName = getOldValue(self, services, 'hive-site', 'ambari.hive.db.schema.name')
        oldDBType = getOldValue(self, services, 'hive-env', 'hive_database')
        if (hiveServerHost is not None):
            if ((hiveDBConnectionURL and ('//localhost' in hiveDBConnectionURL)) or oldSchemaName or oldDBType or (protocol and hiveDBConnectionURL and (not hiveDBConnectionURL.startswith(protocol)))):
                dbConnection = self.getDBConnectionString(hiveEnvProperties['hive_database']).format(hiveServerHost['Hosts']['host_name'], hiveSiteProperties['ambari.hive.db.schema.name'])
                putHiveProperty('javax.jdo.option.ConnectionURL', dbConnection)
    servicesList = [service['StackServices']['service_name'] for service in services['services']]
    if ('PIG' in servicesList):
        ambari_user = self.getAmbariUser(services)
        ambariHostName = socket.getfqdn()
        webHcatSiteProperty = self.putProperty(configurations, 'webhcat-site', services)
        webHcatSiteProperty('webhcat.proxyuser.{0}.hosts'.format(ambari_user), ambariHostName)
        webHcatSiteProperty('webhcat.proxyuser.{0}.groups'.format(ambari_user), '*')
        old_ambari_user = self.getOldAmbariUser(services)
        if (old_ambari_user is not None):
            webHcatSitePropertyAttributes = self.putPropertyAttribute(configurations, 'webhcat-site')
            webHcatSitePropertyAttributes('webhcat.proxyuser.{0}.hosts'.format(old_ambari_user), 'delete', 'true')
            webHcatSitePropertyAttributes('webhcat.proxyuser.{0}.groups'.format(old_ambari_user), 'delete', 'true')
